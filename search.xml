<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>pandas将多列带时间戳的Series合并为单个DataFrame</title>
    <url>/2020/05/04/pandas%E5%B0%86%E5%A4%9A%E5%88%97%E5%B8%A6%E6%97%B6%E9%97%B4%E6%88%B3%E7%9A%84Series%E5%90%88%E5%B9%B6%E4%B8%BA%E5%8D%95%E4%B8%AADataFrame/</url>
    <content><![CDATA[<p>﻿<strong>背景：</strong><br>遇到这样的需求:<br>将多列这样以时间戳为index的Series数据拼接为整体的DataFrame（只带有一列index）<br>数据举例：<br>(1) 温度数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-03-20 00:00:00    10.911639</span><br><span class="line">2020-03-20 00:30:00    10.561648</span><br><span class="line">2020-03-20 01:00:00    10.410831</span><br><span class="line">2020-03-20 01:30:00     9.993831</span><br><span class="line">2020-03-20 02:00:00     9.996133</span><br><span class="line">2020-03-20 02:30:00     9.807382</span><br><span class="line">2020-03-20 03:00:00     9.831737</span><br><span class="line">2020-03-20 03:30:00     9.767458</span><br><span class="line">2020-03-20 04:00:00     9.789868</span><br><span class="line">2020-03-20 04:30:00     9.993025</span><br><span class="line">2020-03-20 05:00:00    10.203707</span><br><span class="line">2020-03-20 05:30:00    10.460783</span><br><span class="line">2020-03-20 06:00:00    10.900585</span><br><span class="line">2020-03-20 06:30:00    11.154725</span><br><span class="line">2020-03-20 07:00:00    11.765203</span><br><span class="line">2020-03-20 07:30:00    12.377077</span><br><span class="line">2020-03-20 08:00:00    13.013389</span><br><span class="line">2020-03-20 08:30:00    13.685595</span><br><span class="line">2020-03-20 09:00:00    14.327092</span><br><span class="line">2020-03-20 09:30:00    14.862767</span><br><span class="line">2020-03-20 10:00:00    15.264174</span><br></pre></td></tr></table></figure>

<p>(2) 湿度数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-03-20 00:00:00    30.071777</span><br><span class="line">2020-03-20 00:30:00    31.718174</span><br><span class="line">2020-03-20 01:00:00    32.415719</span><br><span class="line">2020-03-20 01:30:00    33.542252</span><br><span class="line">2020-03-20 02:00:00    33.725316</span><br><span class="line">2020-03-20 02:30:00    34.507023</span><br><span class="line">2020-03-20 03:00:00    34.402693</span><br><span class="line">2020-03-20 03:30:00    35.050728</span><br><span class="line">2020-03-20 04:00:00    35.082839</span><br><span class="line">2020-03-20 04:30:00    34.889389</span><br><span class="line">2020-03-20 05:00:00    34.481423</span><br><span class="line">2020-03-20 05:30:00    33.377774</span><br><span class="line">2020-03-20 06:00:00    31.306436</span><br><span class="line">2020-03-20 06:30:00    30.868772</span><br><span class="line">2020-03-20 07:00:00    29.368311</span><br><span class="line">2020-03-20 07:30:00    27.515762</span><br><span class="line">2020-03-20 08:00:00    24.488863</span><br><span class="line">2020-03-20 08:30:00    22.346596</span><br><span class="line">2020-03-20 09:00:00    19.126895</span><br><span class="line">2020-03-20 09:30:00    17.111340</span><br><span class="line">2020-03-20 10:00:00    13.799469</span><br></pre></td></tr></table></figure>

<p>解决的问题就是：保留一列时间戳作index，把剩下多列的Series.values拼接在一起。<br>（1）首先，找一组Series作为第一列,比如温度，先将series转换DataFrame:<br>self.preData[0]表示Series的温度数据，本文在self.preData列表中存放了5组上面说的Series数据。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame &#x3D; &#123;&#39;Date Time&#39;: self.preData[0].index, &#39;Temperature&#39;: self.preData[0].values&#125;</span><br><span class="line">frame &#x3D; pd.DataFrame(frame)	# 转换DataFrame</span><br></pre></td></tr></table></figure>

<p>（2）将第一列时间戳作为index</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&#39;Date Time&#39;] &#x3D; pd.to_datetime(frame[&#39;Date Time&#39;])</span><br><span class="line">frame.set_index(&#39;Date Time&#39;, inplace&#x3D;True)</span><br></pre></td></tr></table></figure>

<p>（3）按列拼接</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frame[&#39;Humidity&#39;] &#x3D; self.preData[1].values      # 温度列的DataFrame，与其他列的Series拼接</span><br><span class="line">frame[&#39;Wind&#39;] &#x3D; self.preData[2].values</span><br><span class="line">frame[&#39;WindSpeed&#39;] &#x3D; self.preData[3].values</span><br><span class="line">frame[&#39;itPower&#39;] &#x3D; self.preData[4].values</span><br></pre></td></tr></table></figure>

<p>因为列还算少，可直接指定列名。列太多可能要另想办法，希望对您有帮助~</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>手把手教你用yolov3模型实现目标检测(三)-VOC数据集制作</title>
    <url>/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%B8%89)-VOC%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/</url>
    <content><![CDATA[<p>﻿写在前面：</p>
<p>网上关于数据标注的文章已有很多，大多数都会有一些细节问题，比如怎样爬取网上的原始图片数据，如何批量重命名？数据集怎样划分为训练集，测试集，验证集？？？标注的数据放置的目录结构不对导致训练报错的问题等等，而这些问题，在本篇文章中都考虑到了，所以只要你按照步骤一步步来，并且使用本文中的代码，将会避免遇到上面所说的问题：</p>
<p>我们已经知道，物体检测，简言之就是框出图像中的目标物体，并给出框的位置和置信度，就像下图这样:<br><img src="https://img-blog.csdnimg.cn/2019112820291923.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>置信度在终端输出了：<br><img src="https://img-blog.csdnimg.cn/20191128202948303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1、标注工具labelImg"><a href="#1、标注工具labelImg" class="headerlink" title="1、标注工具labelImg"></a>1、标注工具labelImg</h3><p>是的，当然要用强大的labelImg，貌似记得直接可以pip install labelImg，还是查一下如何安装吧，很简单的<br>界面长这个样子：<br><img src="https://img-blog.csdnimg.cn/20191128203519408.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下面我们<strong>标注PascalVOC数据集：</strong><br>首先下载VOC2007格式的原始数据集：<br><a href="http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar" target="_blank" rel="noopener">http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar</a><br><a href="http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar" target="_blank" rel="noopener">http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar</a><br>下载完成后，目录应该是这样式儿的：<br><img src="https://img-blog.csdnimg.cn/20191128204038263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>如果不需要其中的图片，直接删除，只保留空的目录结构。</p>
<p>其中，Annotations存放标注后的标签文件(.xml)<br>ImageSets存放你的训练集、测试集、验证集等的配置文件（文件中存放图片路径）<br>JPEGImages存放原始图片数据<br>SegmentationClass<br>SegmentationObject我们不使用<br>labelImg标注工具选择 打开目录-&gt;打开ImageSets目录，选择改变存放目录，存放xml到Annotations目录</p>
<p>labelImg使用简单<strong>快捷键</strong>：<br>A / D键，左右选择图片，W：开始标注，ctrl+s保存。<br><strong>标注需遵守的基本规则：</strong><br><img src="https://img-blog.csdnimg.cn/20200109120155362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>—————————————-分割线—————————————–<br>那知道怎么标注后，如何获取我们想要的图片数据：<br>请移步：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://blog.csdn.net/Hu_helloworld/article/details/103044737</span><br></pre></td></tr></table></figure>

<p>网上爬虫等下载到图片后，如何批量重命名？<br>一个小脚本：<br>食用时，请修改self.path重命名图片的路径，我会专门mkdir一个rename目录，免得出错。<br>而且重点是，VOC数据集格式是规定这样的：占6位数，所以必要是要修改dst那行的几个’000’,你一试就行<br><img src="https://img-blog.csdnimg.cn/2019112820524229.png" alt="在这里插入图片描述"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">class ImageRename():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.path = <span class="string">'/home/hujinlei/dev/YOLOv3-dev/darknet/scripts/VOCdevkit/VOC2007/rename'</span></span><br><span class="line"></span><br><span class="line">    def rename(self):</span><br><span class="line">        filelist = os.listdir(self.path)</span><br><span class="line">        total_num = len(filelist)</span><br><span class="line"></span><br><span class="line">        i = 2548</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> filelist:</span><br><span class="line">            <span class="keyword">if</span> item.endswith(<span class="string">'.jpg'</span>):</span><br><span class="line">                src = os.path.join(os.path.abspath(self.path), item)</span><br><span class="line">                dst = os.path.join(os.path.abspath(self.path), <span class="string">'000'</span> + format(str(i), <span class="string">'0&gt;3s'</span>) + <span class="string">'.jpg'</span>)</span><br><span class="line">                os.rename(src, dst)</span><br><span class="line">                <span class="built_in">print</span> (<span class="string">'converting %s to %s ...'</span>%(src, dst))</span><br><span class="line">                i = i + 1</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">'total %d to rename &amp; converted %d jpgs'</span> % (total_num, i))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    newname = ImageRename()</span><br><span class="line">    newname.rename()</span><br></pre></td></tr></table></figure>

<p>都标注好，重命名ok以后。<br>在VOC2007目录下，也就是这个目录下：<br><img src="https://img-blog.csdnimg.cn/20191128205523268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>以下脚本可以给整个数据集划分为：训练集、测试集、验证集.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">将voc_2007格式的数据集划分下训练集、测试集和验证集</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainval_percent = 0.96</span><br><span class="line">train_percent = 0.9</span><br><span class="line">xmlfilepath = <span class="string">'Annotations'</span></span><br><span class="line">txtsavepath = <span class="string">'ImageSets/Main'</span></span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num=len(total_xml)</span><br><span class="line">list=range(num)</span><br><span class="line">tv=int(num*trainval_percent)</span><br><span class="line">tr=int(tv*train_percent)</span><br><span class="line">trainval= random.sample(list,tv)</span><br><span class="line">train=random.sample(trainval,tr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ftrainval = open(<span class="string">'ImageSets/Main/trainval.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">ftest = open(<span class="string">'ImageSets/Main/test.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">ftrain = open(<span class="string">'ImageSets/Main/train.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">fval = open(<span class="string">'ImageSets/Main/val.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i  <span class="keyword">in</span> list:</span><br><span class="line">    name=total_xml[i][:-4]+<span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            ftrain.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftest.write(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest .close()</span><br></pre></td></tr></table></figure>

<p>会在目录下，生成ImageSets/Main/<br><img src="https://img-blog.csdnimg.cn/20191128205739103.png" alt="在这里插入图片描述"><br>最后，在工程项目的/scripts目录下，修改voc_label.py文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line">import pickle</span><br><span class="line">import os</span><br><span class="line">from os import listdir, getcwd</span><br><span class="line">from os.path import join</span><br><span class="line"><span class="comment">#将下面的sets和classes改为自己对应的</span></span><br><span class="line"><span class="comment">#sets=[('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test')]</span></span><br><span class="line"><span class="comment">#classes = ["aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"]</span></span><br><span class="line"></span><br><span class="line">sets=[(<span class="string">'2007'</span>, <span class="string">'train'</span>), (<span class="string">'2007'</span>, <span class="string">'val'</span>), (<span class="string">'2007'</span>, <span class="string">'test'</span>)]</span><br><span class="line">classes = [<span class="string">"Fire extinguisher"</span>,<span class="string">"Fire extinguisher box"</span>,<span class="string">"Fire hydrant"</span>,<span class="string">"trolley"</span>,<span class="string">"ladder"</span>]</span><br><span class="line"></span><br><span class="line">def convert(size, box):</span><br><span class="line">    dw = 1./(size[0])</span><br><span class="line">    dh = 1./(size[1])</span><br><span class="line">    x = (box[0] + box[1])/2.0 - 1</span><br><span class="line">    y = (box[2] + box[3])/2.0 - 1</span><br><span class="line">    w = box[1] - box[0]</span><br><span class="line">    h = box[3] - box[2]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="built_in">return</span> (x,y,w,h)</span><br><span class="line"></span><br><span class="line">def convert_annotation(year, image_id):</span><br><span class="line">    in_file = open(<span class="string">'VOCdevkit/VOC%s/Annotations/%s.xml'</span>%(year, image_id))</span><br><span class="line">    out_file = open(<span class="string">'VOCdevkit/VOC%s/labels/%s.txt'</span>%(year, image_id), <span class="string">'w'</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">'size'</span>)</span><br><span class="line">    w = int(size.find(<span class="string">'width'</span>).text)</span><br><span class="line">    h = int(size.find(<span class="string">'height'</span>).text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.iter(<span class="string">'object'</span>):</span><br><span class="line">        difficult = obj.find(<span class="string">'difficult'</span>).text</span><br><span class="line">        cls = obj.find(<span class="string">'name'</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls not <span class="keyword">in</span> classes or int(difficult)==1:</span><br><span class="line">            <span class="built_in">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">'bndbox'</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">'xmin'</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">'xmax'</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">'ymin'</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">'ymax'</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(str(cls_id) + <span class="string">" "</span> + <span class="string">" "</span>.join([str(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">wd = getcwd()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year, image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(<span class="string">'VOCdevkit/VOC%s/labels/'</span>%(year)):</span><br><span class="line">        os.makedirs(<span class="string">'VOCdevkit/VOC%s/labels/'</span>%(year))</span><br><span class="line">    image_ids = open(<span class="string">'VOCdevkit/VOC%s/ImageSets/Main/%s.txt'</span>%(year, image_set)).<span class="built_in">read</span>().strip().split()</span><br><span class="line">    list_file = open(<span class="string">'%s_%s.txt'</span>%(year, image_set), <span class="string">'w'</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">'%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\n'</span>%(wd, year, image_id))</span><br><span class="line">        convert_annotation(year, image_id)</span><br><span class="line">    list_file.close()</span><br><span class="line"></span><br><span class="line">os.system(<span class="string">"cat 2007_train.txt 2007_val.txt &gt; train.txt"</span>)</span><br><span class="line">os.system(<span class="string">"cat 2007_train.txt 2007_val.txt 2007_test.txt &gt; train.all.txt"</span>)</span><br></pre></td></tr></table></figure>

<p>运行此脚本，会在当前目录，产生以下文件：<br><img src="https://img-blog.csdnimg.cn/20191128210041486.png" alt="在这里插入图片描述"><br>其中，2007_test.txt测试集<br>    2007_train.txt训练集<br>    2007_val.txt验证集<br>    我们使用2007_test.txt和train.txt就可以。</p>
<p>=============================================================<br>日后在更</p>
]]></content>
      <categories>
        <category>yolov3目标检测</category>
      </categories>
      <tags>
        <tag>yolov3目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>手把手教你用yolov3模型实现目标检测教程(一) - 环境配置</title>
    <url>/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%B8%80)-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>﻿## 手把手教你用yolov3模型实现目标检测(一)</p>
<p>写在前面：<br>由于项目需要，使用yolov3模型做了各种现实场景物体的目标检测。做完了过了好长时间，感觉有些遗忘，还是该留下点东西，方便自己查找，也希望能惠及他人。<br>同时，为了督促自己补充理论体系，尽量做到知其然知其所以然</p>
<h3 id="1、环境配置"><a href="#1、环境配置" class="headerlink" title="1、环境配置"></a>1、环境配置</h3><p>首先，本教程是完全在ubuntu 18.04下进行的，你能找到的成熟框架不外乎以下三个：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;qqwweee&#x2F;keras-yolo3 ，基于keras编写</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;pjreddie&#x2F;darknet ，基于c++编写</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;AlexeyAB&#x2F;darknet ， 基于c++编写</span><br></pre></td></tr></table></figure>

<p>其中，第一个keras-yolo3需要搭建tensorflow-gpu,keras等很多环境。比较麻烦，有时间学习可以用这个。<br><strong>推荐使用</strong>第二个官方框架pjreddie/darknet，官网(教程)如下：<a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="noopener">https://pjreddie.com/darknet/yolo/</a><br>第三个AlexeyAB/darknet项目近期一直在维护，而且文档特别详细。但个人感觉第二个官方框架实践起来更简单。<br>建议训练和检测过程中有任何问题，先到第二第三个仓库的issues中查找，<strong>也许会找到你想要的</strong>。<br>好，那我们开始：<br>先下载该项目：<a href="https://github.com/pjreddie/darknet" target="_blank" rel="noopener">https://github.com/pjreddie/darknet</a></p>
<h4 id="CPU-GPU编译："><a href="#CPU-GPU编译：" class="headerlink" title="CPU/GPU编译："></a>CPU/GPU编译：</h4><p>编译过程中，检查环境：<br>我的环境：cmake version 3.10.2; 别的版本应该也可<br>Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49)<br>教程也很清楚哦：<a href="https://pjreddie.com/darknet/install/" target="_blank" rel="noopener">https://pjreddie.com/darknet/install/</a></p>
<p><strong>注意</strong>：darknet不支持gcc和g++6以上的版本，而ubuntu18.04默认安装的gcc-7<br>因此，需要将gcc和g++分别降级：<br><strong>（1）</strong> gcc/g++降级为4.8版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">	(1)在Ubuntu 16.04上安装老版gcc十分简单，直接用apt-get命令下载即可.</span><br><span class="line">sudo apt-get install gcc-4.8</span><br><span class="line">（2）安装完成后输入命令gcc --verison查看gcc的版本,此时还是高版本</span><br><span class="line">（3）查看版本gcc-4.8版本是否安装成功</span><br><span class="line">ls &#x2F;usr&#x2F;bin&#x2F;gcc*</span><br><span class="line">（4）输入命令设置默认版本:</span><br><span class="line">sudo update-alternatives --install &#x2F;usr&#x2F;bin&#x2F;gcc gcc &#x2F;usr&#x2F;bin&#x2F;gcc-4.8 100</span><br><span class="line">（5）查看默认结果（非必须）</span><br><span class="line">sudo update-alternatives --config gcc</span><br><span class="line">（6）最终gcc --version 发现变成4.8版本了</span><br><span class="line"></span><br><span class="line">g++的降级，只需把上面gcc改称g++。gcc和g++的版本应该必须一致。</span><br></pre></td></tr></table></figure>

<p><strong>CPU:</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd darknet-master </span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>就完事了，一般不会有问题。</p>
<p><strong>GPU:</strong><br>yolov3是十分高效快速的！这点不用过多介绍，虽然CPU版本以及很快，但GPU号称快了500倍！<br>修改根目录下的makefile文件的GPU和CUDNN为1即可：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GPU&#x3D;1</span><br><span class="line">CUDNN&#x3D;1</span><br><span class="line">OPENCV&#x3D;0</span><br><span class="line">OPENMP&#x3D;0</span><br><span class="line">DEBUG&#x3D;0</span><br></pre></td></tr></table></figure>

<p>改完然后同样的，根目录 -&gt; make就ok了<br>我的环境：<br>ubuntu18.04+CUDA9.0+CUDNN7+nvidia1050 4G显存<br>安装教程：（很多链接）<br><a href="https://blog.csdn.net/Hu_helloworld/article/details/102614562" target="_blank" rel="noopener">https://blog.csdn.net/Hu_helloworld/article/details/102614562</a><br>CPU和GPU实测yolov3检测同一张图片，cpu到7、8s,GPU就是0.几s的量级<br>如果对于精确度要求不是特别高，而机器配置低对速度要求更高，建议使用yolov3-tiny版本（轻量，速度也可）</p>
<h3 id="2、下载与训练模型"><a href="#2、下载与训练模型" class="headerlink" title="2、下载与训练模型"></a>2、下载与训练模型</h3><p>yolov3.weights<br>模型文件包括<strong>.cfg</strong>配置文件和<strong>.weights</strong>权重文件<br>.cfg文件在项目中 /cfg目录<br>下载权重文件：<br><a href="https://pjreddie.com/media/files/yolov3.weights" target="_blank" rel="noopener">https://pjreddie.com/media/files/yolov3.weights</a><br>或者<br><a href="https://pjreddie.com/media/files/yolov3-tiny.weights" target="_blank" rel="noopener">https://pjreddie.com/media/files/yolov3-tiny.weights</a></p>
<h3 id="3、使用预训练模型测试目标检测"><a href="#3、使用预训练模型测试目标检测" class="headerlink" title="3、使用预训练模型测试目标检测"></a>3、使用预训练模型测试目标检测</h3><p>最简单的检测命令，在根目录下执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;darknet detect cfg&#x2F;yolov3.cfg yolov3.weights data&#x2F;dog.jpg</span><br></pre></td></tr></table></figure>

<p>另一种命令写法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;darknet detector test cfg&#x2F;coco.data cfg&#x2F;yolov3.cfg yolov3.weights data&#x2F;dog.jpg</span><br></pre></td></tr></table></figure>

<p>您将看到以下输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">layer     filters    size              input                output</span><br><span class="line">    0 conv     32  3 x 3 &#x2F; 1   416 x 416 x   3   -&gt;   416 x 416 x  32  0.299 BFLOPs</span><br><span class="line">    1 conv     64  3 x 3 &#x2F; 2   416 x 416 x  32   -&gt;   208 x 208 x  64  1.595 BFLOPs</span><br><span class="line">    .......</span><br><span class="line">  105 conv    255  1 x 1 &#x2F; 1    52 x  52 x 256   -&gt;    52 x  52 x 255  0.353 BFLOPs</span><br><span class="line">  106 detection</span><br><span class="line">truth_thresh: Using default &#39;1.000000&#39;</span><br><span class="line">Loading weights from yolov3.weights...Done!</span><br><span class="line">data&#x2F;dog.jpg: Predicted in 0.029329 seconds.</span><br><span class="line">dog: 99%</span><br><span class="line">truck: 93%</span><br><span class="line">bicycle: 99%</span><br></pre></td></tr></table></figure>

<p>其中data文件夹中提供了一些示例图像，以备不时之需。尝试data/eagle.jpg，data/dog.jpg，data/person.jpg，或data/horses.jpg！<br>以下是我训练tiny模型的检测结果<br><img src="https://img-blog.csdnimg.cn/20191128200545339.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>到此位置我们可以使用官方提供的预训练模型进行目标检测，后面想在我们自己的场景下使用还需要自己训练样本，调整参数，调用自己的模型进行检测。<br>下篇介绍，标注自己的PASCAL VOC图片数据集，训练自己的yolov3-tiny模型。</p>
]]></content>
      <categories>
        <category>yolov3目标检测</category>
      </categories>
      <tags>
        <tag>yolov3目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>手把手教你用yolov3模型实现目标检测教程(二)-样本数据获取</title>
    <url>/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%BA%8C)-%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96/</url>
    <content><![CDATA[<p>写在前面：</p>
<p>听说你在训练时缺数据？不存在的o(<em>￣▽￣</em>)ブ</p>
<p><strong>数据来源于百度、google图片</strong></p>
<p>曾部分参考文章：<a href="https://blog.csdn.net/wobeatit/article/details/79559314" target="_blank" rel="noopener">https://blog.csdn.net/wobeatit/article/details/79559314</a></p>
<p><strong>因为google图片质量较好，推荐使用方法1：<br>利用googleimagesdownload工具爬取google 图片，<br>但需要fanqiang,能访问goolge图片，可以找插件/搭建亚马逊AWS服务器解决</strong></p>
<p>以下方法仅在ubuntu下测试过</p>
<h4 id="1、ubuntu下-使用工具google-images-download，爬取google-images"><a href="#1、ubuntu下-使用工具google-images-download，爬取google-images" class="headerlink" title="1、ubuntu下 使用工具google-images-download，爬取google images"></a>1、ubuntu下 使用工具google-images-download，爬取google images</h4><p><strong>若有梯子，能访问google images,可以采用这种方式，稳定，十分推荐！</strong><br>官方教程如下<br>项目地址：<a href="https://github.com/hardikvasa/google-images-download" target="_blank" rel="noopener">googleimagesdownload</a><br>工具安装：<a href="https://google-images-download.readthedocs.io/en/latest/installation.html" target="_blank" rel="noopener">安装googleimagesdownload</a><br>使用示例：<a href="https://google-images-download.readthedocs.io/en/latest/examples.html#" target="_blank" rel="noopener">使用示例</a></p>
<p>可直接pip安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install google_images_download</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">googleimagesdownload -k &quot;灭火器箱&quot; --size medium -l 1000 --chromedriver .&#x2F;chromedriver</span><br></pre></td></tr></table></figure>

<p>命令行   输入参数解释：<br>-k “要搜索的图片”<br>–size 指定图片大小，如medium<br>-l 限制下载的数量<br>–chromedriver 指定谷歌驱动的路径<br>Chrome驱动下载安装教程很多：<a href="https://blog.csdn.net/qq_41188944/article/details/79039690" target="_blank" rel="noopener">https://blog.csdn.net/qq_41188944/article/details/79039690</a></p>
<p>像这样 -l 限制下载1000张图片，因为图片版权的原因，实际下载到409张，可以更改搜索词再次下载。<br>google images 的图片质量较高，基本算是标注好的图片。<br>类似这种：<img src="https://img-blog.csdnimg.cn/20191113214031122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>该工具会在终端目录创建download文件夹以放置爬取的图片</p>
<h4 id="2、python-脚本爬取百度图片"><a href="#2、python-脚本爬取百度图片" class="headerlink" title="2、python 脚本爬取百度图片"></a>2、python 脚本爬取百度图片</h4><p>(1) 安装 Chrome 浏览器 和 Chrome驱动<br>        Chrome驱动安装：<a href="https://blog.csdn.net/qq_41188944/article/details/79039690" target="_blank" rel="noopener">https://blog.csdn.net/qq_41188944/article/details/79039690</a></p>
<p>(2) pip install selenium安装selenium库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#*******本脚本运行时需要本机安装 Chrome 浏览器以及Chrome的驱动，同时需要selenium库的支撑********</span><br><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.webdriver.chrome.options import Options</span><br><span class="line">import time  </span><br><span class="line">import urllib.request</span><br><span class="line">from bs4 import BeautifulSoup as bs</span><br><span class="line">import re  </span><br><span class="line">import os  </span><br><span class="line">#****************************************************</span><br><span class="line">#base_url_part1 &#x3D; &#39;https:&#x2F;&#x2F;image.baidu.com&#x2F;search&#x2F;index?tn&#x3D;baiduimage&amp;ipn&#x3D;r&amp;ct&#x3D;201326592&amp;cl&#x3D;2&amp;lm&#x3D;-1&amp;st&#x3D;-1&amp;fm&#x3D;index&amp;fr&#x3D;&amp;hs&#x3D;0&amp;xthttps&#x3D;111111&amp;sf&#x3D;1&amp;fmq&#x3D;&amp;pv&#x3D;&amp;ic&#x3D;0&amp;nc&#x3D;1&amp;z&#x3D;&amp;se&#x3D;1&amp;showtab&#x3D;0&amp;fb&#x3D;0&amp;width&#x3D;&amp;height&#x3D;&amp;face&#x3D;0&amp;istype&#x3D;2&amp;ie&#x3D;utf-8&amp;word&#x3D;&#39;</span><br><span class="line">#base_url_part2 &#x3D; &#39;&amp;oq&#x3D;bagua&amp;rsp&#x3D;0&#39; # base_url_part1以及base_url_part2都是固定不变的，无需更改</span><br><span class="line">base_url_part1 &#x3D; &#39;https:&#x2F;&#x2F;www.shutterstock.com&#x2F;zh&#x2F;search&#x2F;&#39;</span><br><span class="line">base_url_part2 &#x3D; &#39;&#39; # base_url_part1以及base_url_part2都是固定不变的，无需更改</span><br><span class="line">search_query &#x3D; &#39;灭火器&#39; # 检索的关键词，可自行更改</span><br><span class="line">location_driver &#x3D; &#39;&#x2F;usr&#x2F;bin&#x2F;chromedriver&#39; # Chrome驱动程序在电脑中的位置</span><br><span class="line"> </span><br><span class="line">class Crawler:</span><br><span class="line">	def __init__(self):</span><br><span class="line">		self.url &#x3D; base_url_part1 + search_query + base_url_part2</span><br><span class="line"> </span><br><span class="line">	# 启动Chrome浏览器驱动</span><br><span class="line">	def start_brower(self):</span><br><span class="line">		chrome_options &#x3D; Options()</span><br><span class="line">		chrome_options.add_argument(&quot;--disable-infobars&quot;)</span><br><span class="line">		# 启动Chrome浏览器  </span><br><span class="line">		driver &#x3D; webdriver.Chrome(executable_path&#x3D;location_driver, chrome_options&#x3D;chrome_options)  </span><br><span class="line">		# 最大化窗口，因为每一次爬取只能看到视窗内的图片</span><br><span class="line">		driver.maximize_window()  </span><br><span class="line">		# 浏览器打开爬取页面  </span><br><span class="line">		driver.get(self.url)  </span><br><span class="line">		return driver</span><br><span class="line"> </span><br><span class="line">	def downloadImg(self, driver):  </span><br><span class="line">		t &#x3D; time.localtime(time.time())</span><br><span class="line">		foldername &#x3D; str(t.__getattribute__(&quot;tm_year&quot;)) + &quot;-&quot; + str(t.__getattribute__(&quot;tm_mon&quot;)) + &quot;-&quot; + \</span><br><span class="line">					 str(t.__getattribute__(&quot;tm_mday&quot;)) # 定义文件夹的名字</span><br><span class="line">		picpath &#x3D; &#39;&#x2F;home&#x2F;hujinlei&#x2F;dev&#x2F;DataSet&#x2F;BaiduImage&#x2F;%s&#39; %(foldername) # 下载到的本地目录</span><br><span class="line">		# 路径不存在时创建一个 </span><br><span class="line">		if not os.path.exists(picpath): os.makedirs(picpath)</span><br><span class="line">		# 记录下载过的图片地址，避免重复下载</span><br><span class="line">		img_url_dic &#x3D; &#123;&#125; </span><br><span class="line">		x &#x3D; 0  </span><br><span class="line">		# 当鼠标的位置小于最后的鼠标位置时,循环执行</span><br><span class="line">		pos &#x3D; 0     </span><br><span class="line">		for i in range(80): # 此处可自己设置爬取范围，本处设置为1，那么不会有下滑出现</span><br><span class="line">			pos +&#x3D; 500 # 每次下滚500</span><br><span class="line">			js &#x3D; &quot;document.documentElement.scrollTop&#x3D;%d&quot; %pos    </span><br><span class="line">			driver.execute_script(js)  </span><br><span class="line">			time.sleep(2)</span><br><span class="line">			# 获取页面源码</span><br><span class="line">			html_page &#x3D; driver.page_source</span><br><span class="line">			# 利用Beautifulsoup4创建soup对象并进行页面解析</span><br><span class="line">			soup &#x3D; bs(html_page, &quot;html.parser&quot;)</span><br><span class="line">			# 通过soup对象中的findAll函数图像信息提取</span><br><span class="line">			imglist &#x3D; soup.findAll(&#39;img&#39;, &#123;&#39;src&#39;:re.compile(r&#39;https:.*\.(jpg|png)&#39;)&#125;)</span><br><span class="line"> </span><br><span class="line">			for imgurl in imglist:  </span><br><span class="line">				if imgurl[&#39;src&#39;] not in img_url_dic:</span><br><span class="line">					target &#x3D; &#39;&#123;&#125;&#x2F;&#123;&#125;.jpg&#39;.format(picpath, x)</span><br><span class="line">					img_url_dic[imgurl[&#39;src&#39;]] &#x3D; &#39;&#39; </span><br><span class="line">					urllib.request.urlretrieve(imgurl[&#39;src&#39;], target)  </span><br><span class="line">					x +&#x3D; 1  </span><br><span class="line">					</span><br><span class="line">	def run(self):</span><br><span class="line">		print (&#39;\t\t\t**************************************\n\t\t\t**\t\tWelcome to Use Spider\t\t**\n\t\t\t**************************************&#39;)  </span><br><span class="line">		driver&#x3D;self.start_brower()</span><br><span class="line">		self.downloadImg(driver)</span><br><span class="line">		driver.close()</span><br><span class="line">		print(&quot;Download has finished.&quot;)</span><br><span class="line"> </span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:  </span><br><span class="line">	craw &#x3D; Crawler() </span><br><span class="line">	craw.run()</span><br></pre></td></tr></table></figure>


<p>3、如何批量重命名下载的图片 ， 制作VOC COCO等数据集<br>以后补充</p>
]]></content>
      <categories>
        <category>yolov3目标检测</category>
      </categories>
      <tags>
        <tag>yolov3目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>时间序列教程之Prophet</title>
    <url>/2020/05/04/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%99%E7%A8%8B%E4%B9%8BProphet/</url>
    <content><![CDATA[<p>hi~ 这里是时间序列预测模型(二) 之 Prophet</p>
]]></content>
      <categories>
        <category>时间序列预测</category>
      </categories>
      <tags>
        <tag>时间序列预测</tag>
      </tags>
  </entry>
  <entry>
    <title>时间序列教程之arima</title>
    <url>/2020/05/04/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%99%E7%A8%8B%E4%B9%8Barima/</url>
    <content><![CDATA[<p>﻿最近接触时间序列较多，在借鉴很多人的知识之后，特此总结一下。目前关于时间序列数据分析预测大致有三种主流方法：<br><strong>1、ARIMA系列方法<br>2、facebook开源的Prophet模型<br>3、LSTM时间序列预测</strong></p>
<p>本系列希望在项目和实践的角度，用python实现上述三种方法并做出对比总结。如有不足之处，感谢指出，虚心改正。<br><strong>所需环境：</strong> win10/ubuntu均可，python3.6.x，pandas，numpy，tensorflow2.0，statsmodels，pmdarima…</p>
<p><strong>（1）项目简介</strong><br>本文项目中所用数据为近一段时间内，间隔30分钟采样的气象数据（包括温度、湿度、风速、风向等数据）。在本文的理解中，arima方法仅支持单变量预测，也就是需要单独取出某列进行该列的预测。若想要多变量输入多变量输出，arima方法要拟合多个模型，再整合输入输出。<br><strong>（2）数据介绍</strong><br>数据是我从某气象网站爬取到的气象数据，已经做好数据清洗，后期我会附上数据链接，举例如下：<br><img src="https://img-blog.csdnimg.cn/20200414233949428.png" width="50%" alt=""/><br>表中单位：温度(华氏度)，湿度%，风向可转换角度，风速（mph）<br>读取csv数据，数据清洗：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  def read_temperature():</span><br><span class="line">      # 以首列的日期时间作为时间戳 此处要转换成pandas的DatetimeIndex格式</span><br><span class="line">      csv_data &#x3D; pd.read_csv(&#39;data&#x2F;test_2020.csv&#39;, usecols&#x3D;[0, 1, 2, 3, 4])</span><br><span class="line">      data[&#39;Date Time&#39;] &#x3D; pd.to_datetime(data[&#39;Date Time&#39;])</span><br><span class="line">      data.set_index(&#39;Date Time&#39;, inplace&#x3D;True)</span><br><span class="line">      data &#x3D; data[&#39;Temperature&#39;]  # DatetimeIndex对象</span><br><span class="line">      # 华氏度转摄氏度</span><br><span class="line">      for i in range(len(data)):</span><br><span class="line">          data[i] &#x3D; round(5 &#x2F; 9 * (data[i] - 32))</span><br><span class="line">      # 时间频率重采样</span><br><span class="line">      data &#x3D; data.resample(&#39;30T&#39;).mean()  # 更新频率30分钟，缺省值用临近的后一值补充</span><br><span class="line">      data &#x3D; data.fillna(data.bfill())</span><br><span class="line"># 显示数据</span><br><span class="line">      data.plot(figsize&#x3D;(15, 12))</span><br><span class="line">      plt.show()</span><br><span class="line">      return data</span><br></pre></td></tr></table></figure>

<p>当前数据图：<br><img src="https://img-blog.csdnimg.cn/20200416224817241.png" width="60%" alt=""/><br> <strong>(3) 平稳性检验</strong><br>arima时间序列数据预测首先要保证数据的平稳性，肉眼可以看到当前数据可能有一定上升趋势。但还是要有数据量化这个平稳性，这里我们使用ADF平稳性检验，基于statsmodels库实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def adf_stability_test(self, data): </span><br><span class="line">    # ADF单位根检验：不存在单位根，表示数据平稳。且不能是白噪声数据(随机数)</span><br><span class="line">    x &#x3D; data</span><br><span class="line">    res &#x3D; ts.adfuller(x)</span><br><span class="line">    lb_res &#x3D; lb_test(x, None, True)[1]</span><br><span class="line"></span><br><span class="line">    tag &#x3D; False</span><br><span class="line">    for i in range(len(lb_res)):</span><br><span class="line">        if lb_res[i] &lt; 0.05:</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            print(&#39;序列为白噪声!&#39;)</span><br><span class="line">            tag &#x3D; True</span><br><span class="line">            break</span><br><span class="line">    if res[0] &lt; res[4][&#39;1%&#39;] and res[0] &lt; res[4][&#39;5%&#39;] and res[0] &lt; res[4][&#39;10%&#39;] and res[1] &lt; 0.05 and not tag:</span><br><span class="line">        print(&#39;平稳序列！非白噪声&#39;)</span><br><span class="line">        # plt.plot(lb_test(x, None, True)[1])</span><br><span class="line">        # plt.ylabel(&#39;p-Value&#39;)</span><br><span class="line">        # plt.show()</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure>

<p>adfuller方法返回值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(-6.260374222209651, 4.237742412839035e-08, 5, 906, &#123;&#39;1%&#39;: -3.4375883271133243, &#39;5%&#39;: -2.8647353885968214, &#39;10%&#39;: -2.568471435365895&#125;, 1615.9162778870964)</span><br></pre></td></tr></table></figure>

<p>ADF单位根检验，如果序列平稳，就不存在单位根；否则，就会存在单位根。该检验先假设序列不平稳，存在单位根。如果得到的显著性检验统计量小于三个置信度（10%，5%，1%），则对应有（90%，95，99%）的把握来拒绝原假设 -&gt;序列平稳。<br>adfuller的返回值意义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">adf：Test statistic，T检验，假设检验值。</span><br><span class="line">p-value：假设检验结果。</span><br><span class="line">usedlag：使用的滞后阶数。</span><br><span class="line">nobs：用于ADF回归和计算临界值用到的观测值数目。</span><br><span class="line">icbest：如果autolag不是None的话，返回最大的信息准则值。</span><br><span class="line">resstore：将结果合并为一个dummy。</span><br></pre></td></tr></table></figure>

<p>具体原理我也不是很懂，只需知道adf值，也就是本文的-6.260374222209651 均小于（10%，5%，1%）三个置信度的值，且p-value &lt; 0.05时能够较好的拒绝原假设，表示序列平稳。<br>若序列不平稳，需要对序列连续差分，直到序列平稳，对差分后的序列进行预测，再将预测结果逆差分，得到我们需要的值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def stability_test(self):</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    flag &#x3D; False</span><br><span class="line">    if not self.adf_stability_test(self.data):</span><br><span class="line">        while not self.adf_stability_test(self.data):</span><br><span class="line">            count +&#x3D; 1</span><br><span class="line">            self.data &#x3D; self.data.diff(count)			# 差分</span><br><span class="line">            self.data &#x3D; self.data.fillna(self.data.bfill())	# 缺省值用后一值补充</span><br><span class="line">            flag &#x3D; True</span><br><span class="line">    print(&#39;经过&#123;&#125;次差分，序列平稳&#39;.format(count)) </span><br><span class="line">    return count, flag</span><br></pre></td></tr></table></figure>

<p>count是让序列变平稳的差分次数，<strong>也就是ARIMA(p,d,q)中的d</strong>，记录count值便于后面调pdq参数。flag记录是否经过差分，便于后期作逆差分还原数据。<br>差分操作很容易理解：原数列的后一项减去前一项得到的一组差数列。<br>相当于序列整体后移，空出第一位是空NAN，再与原序列做差</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 1 2 3 4 5 6</span><br><span class="line">3 6 7 8 9 10 12 </span><br><span class="line"># 一阶差分</span><br><span class="line">0 	 1 2 3 4 5 6</span><br><span class="line">NAN  3 1 1 1 1 2</span><br></pre></td></tr></table></figure>

<p>我们知道arima或者是seasonal arima最重要的是（p,d,q）和（P,D,Q,S）这四个参数的确定。<br>而相对准确的方法是计算acf,pacf图，通过观察自相关图和偏相关图，确定拖尾还是截尾等什么鬼的…..我到现在还似懂非懂。总之了解下来是要肉眼观察参数，不能自动化调参…<br>但我们的数据是实时变化的，参数可能变动很大。自动化训练参数很有必要：<br> <strong>(4)  模型参数训练</strong><br>目前了解两种自动确定参数方法：<br>1）<strong>网格搜索</strong>的方法：<br>感觉就是暴力搜索，用一些模型评价标准确定最优的参数，计算量很大复杂度高。不在乎效率也值得一试，此处用AIC准则评价模型，找出AIC评分最小的模型参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def temp_param_optimization(self, data):</span><br><span class="line">    paramBest &#x3D; []</span><br><span class="line">    warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line">    p &#x3D; q &#x3D; range(0, 3)		# 限制pq范围</span><br><span class="line">    pdq &#x3D; [(x[0], self.d, x[1]) for x in list(itertools.product(p, q))]	# 此处的d我们已经得到</span><br><span class="line">    seasonal_pdq &#x3D; [(x[0], self.d, x[1], s) for x in list(itertools.product(p, q))]		# 此处的s是季节性参数，可根据数据指定，变化不大</span><br><span class="line">    </span><br><span class="line">    for param in pdq:</span><br><span class="line">        for param_seasonal in seasonal_pdq:</span><br><span class="line">            try:</span><br><span class="line">                mod &#x3D; sm.tsa.statespace.SARIMAX(data,</span><br><span class="line">                                                order&#x3D;param,</span><br><span class="line">                                                seasonal_order&#x3D;param_seasonal,</span><br><span class="line">                                                enforce_stationarity&#x3D;False,</span><br><span class="line">                                                enforce_invertibility&#x3D;False)</span><br><span class="line"></span><br><span class="line">                results &#x3D; mod.fit()</span><br><span class="line">                paramBest.append([param, param_seasonal, results.aic])</span><br><span class="line">                print(&#39;ARIMA&#123;&#125;x&#123;&#125;12 - AIC:&#123;&#125;&#39;.format(param, param_seasonal, results.aic))</span><br><span class="line">            except:</span><br><span class="line">                continue</span><br><span class="line">    # print(&#39;paramBest:&#39;, paramBest)</span><br><span class="line">    minAic &#x3D; sys.maxsize</span><br><span class="line">    for i in np.arange(len(paramBest)):</span><br><span class="line">        if paramBest[i][2] &lt; minAic:</span><br><span class="line">            minAic &#x3D; paramBest[i][2]</span><br><span class="line">    # print(&quot;minAic:&quot;, minAic)</span><br><span class="line">    for j in np.arange(len(paramBest)):</span><br><span class="line">        if paramBest[j][2] &#x3D;&#x3D; minAic:</span><br><span class="line">            return paramBest[j][0], paramBest[j][1]</span><br></pre></td></tr></table></figure>

<p><strong>2）pmdarima</strong><br>了解过时间序列发现，很多用R语言作时间序列预测的。因为R提供自动训练参数的库auto_arima。也是在项目后期才发现python也有类似的开源库pmdarima，貌似就是模仿R而来的。<br>直接pip install pmdarima -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>，pip安装要记得换源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def auto_parameters(self, data, s_num):</span><br><span class="line">    kpss_diff &#x3D; arima.ndiffs(data, alpha&#x3D;0.05, test&#x3D;&#39;kpss&#39;, max_d&#x3D;s_num)</span><br><span class="line">    adf_diff &#x3D; arima.ndiffs(data, alpha&#x3D;0.05, test&#x3D;&#39;adf&#39;, max_d&#x3D;s_num)</span><br><span class="line">    d &#x3D; max(kpss_diff, adf_diff)</span><br><span class="line">    D &#x3D; arima.nsdiffs(data, s_num)</span><br><span class="line">    </span><br><span class="line">    stepwise_model &#x3D; auto_arima(data, start_p&#x3D;1, start_q&#x3D;1,</span><br><span class="line">                                max_p&#x3D;9, max_q&#x3D;9, max_d&#x3D;3, m&#x3D;s_num,</span><br><span class="line">                                seasonal&#x3D;True, d&#x3D;d, D&#x3D;D, trace&#x3D;True,</span><br><span class="line">                                error_action&#x3D;&#39;ignore&#39;,</span><br><span class="line">                                suppress_warnings&#x3D;True,</span><br><span class="line">                                stepwise&#x3D;True)</span><br><span class="line">    print(&quot;AIC: &quot;, stepwise_model.aic())</span><br><span class="line">    print(stepwise_model.order)		# (p,d,q)</span><br><span class="line">    print(stepwise_model.seasonal_order)	# (P,D,Q,S)</span><br><span class="line">    print(stepwise_model.summary())		# 详细模型</span><br><span class="line">    return stepwise_model.order, stepwise_model.seasonal_order</span><br></pre></td></tr></table></figure>

<p>十分方便的库，arima.ndiffs()，arima.nsdiffs()可以方便的求出最合适的d,和D参数。代码中s_num是自己指定的季节性参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto_arima(data, start_p&#x3D;1, start_q&#x3D;1,</span><br><span class="line">		     max_p&#x3D;9, max_q&#x3D;9, max_d&#x3D;3, m&#x3D;s_num,</span><br><span class="line">		     seasonal&#x3D;True, d&#x3D;d, D&#x3D;D, trace&#x3D;True,</span><br><span class="line">		     error_action&#x3D;&#39;ignore&#39;,</span><br><span class="line">		     suppress_warnings&#x3D;True,</span><br><span class="line">		     stepwise&#x3D;True)</span><br></pre></td></tr></table></figure>

<p>start_p，start_q设置初始p,q参数，max_p，max_q最大值。stepwise=True貌似会直接选择最优参数。参数还有很多，请查阅官方api：<a href="https://alkaline-ml.com/pmdarima/index.html" target="_blank" rel="noopener">https://alkaline-ml.com/pmdarima/index.html</a><br>对比网格搜索的方法，本文觉得两种方法确定的参数几乎相同，但auto_arima训练参数特别快。同样的数据auto_arima要快一半以上。<br><strong>（5）模型预测</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def model_prediction(self, data, param, s_param, n_steps, flag):</span><br><span class="line">    mod &#x3D; sm.tsa.statespace.SARIMAX(data,</span><br><span class="line">                                    order&#x3D;param,</span><br><span class="line">                                    seasonal_order&#x3D;s_param,</span><br><span class="line">                                    enforce_stationarity&#x3D;False,</span><br><span class="line">                                    enforce_invertibility&#x3D;False)</span><br><span class="line">    results &#x3D; mod.fit()</span><br><span class="line"></span><br><span class="line">    pred_uc &#x3D; results.get_forecast(steps&#x3D;n_steps)		# n_steps可指定预测的步数(多少时间间隔)</span><br><span class="line">    pred_ci &#x3D; pred_uc.conf_int()</span><br><span class="line"></span><br><span class="line">    if flag:  # 还原差分</span><br><span class="line">        pred_res &#x3D; pd.Series([data[0]], index&#x3D;[data.index[0]]).append(pred_uc.predicted_mean).cumsum()</span><br><span class="line">        print(&quot;预测结果(℃):  &quot;, pred_res)</span><br><span class="line">        return pred_res</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;预测结果(℃):  &quot;, pred_uc.predicted_mean)</span><br><span class="line">        return pred_uc.predicted_mean</span><br></pre></td></tr></table></figure>

<p>传入参数param，s_param分别对应（pdq）(PDQS)<br>测试数据预测结果：<br><img src="https://img-blog.csdnimg.cn/20200417000446754.png" width="60%" alt=""/></p>
<hr>
<p>4.21更新<br>感觉对于数据的季节性参数设置可能有点迷。比如文中提到的网格搜索的参数s和auto_arima的参数m都是要自己设置的，当然要根据所用数据的频率间隔来设置季节性。我的理解是数据规律的周期性呈现方式。比如，我用的是每30分钟的观测数据，一个月的数据。就可以设置为日周期性30<em>48=1440，一天共48个间隔，m或者s参数设置为48可能比较合适，但还是要针对数据具体分析。<br>如果各位同学可以*</em>科学上网**的话，<a href="https://robjhyndman.com/hyndsight/seasonal-periods/" target="_blank" rel="noopener">https://robjhyndman.com/hyndsight/seasonal-periods/</a>      这位博主关于季节性参数写的比较好！<br>针对一般情况的设置：<br><img src="https://img-blog.csdnimg.cn/20200421112656889.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>时间序列预测</category>
      </categories>
      <tags>
        <tag>时间序列预测</tag>
      </tags>
  </entry>
</search>
