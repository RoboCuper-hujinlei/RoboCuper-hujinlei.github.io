<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>tesseract4.1标注自己的样本训练ocr识别库</title>
      <link href="/2020/05/05/tesseract4-1%E6%A0%87%E6%B3%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A0%B7%E6%9C%AC%E8%AE%AD%E7%BB%83ocr%E8%AF%86%E5%88%AB%E5%BA%93/"/>
      <url>/2020/05/05/tesseract4-1%E6%A0%87%E6%B3%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A0%B7%E6%9C%AC%E8%AE%AD%E7%BB%83ocr%E8%AF%86%E5%88%AB%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>﻿转载自：<br>原文链接：<a href="https://blog.csdn.net/whatday/article/details/38493551" target="_blank" rel="noopener">https://blog.csdn.net/whatday/article/details/38493551</a></p><p>由于tesseract的中文语言包“chi_sim”对中文手写字体或者环境比较复杂的图片，识别正确率不高，因此需要针对特定情况用自己的样本进行训练，提高识别率，通过训练，也可以形成自己的语言库。<br>步骤：</p><p>1、工具准备：</p><p>（1）官方文档：<a href="https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00" target="_blank" rel="noopener">https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00</a></p><p>（2）Java虚拟机，由于jTessBoxEditor的运行依赖Java运行时环境，所以需要安装Java虚拟机。</p><p>下载地址：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p><p>（3）jTessBoxEditor2.0工具，用于调整图片上文字的内容和位置，</p><p>下载地址：<a href="https://sourceforge.net/projects/vietocr/files/jTessBoxEditor/" target="_blank" rel="noopener">https://sourceforge.net/projects/vietocr/files/jTessBoxEditor/</a></p><p>安装包解压后双击里边的“jTessBoxEditor.jar”，或者双击该目录下的“train.bat”脚本文件，就可以打开该工具了。</p><p>2、样本图片准备：（进行训练的样本图片数量越多越好）<br>这里只准备2种不同字体样本进行测试：<br><img src="https://img-blog.csdnimg.cn/20190823091228436.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2019082309123441.png" alt="在这里插入图片描述"><br>3、使用jTessBoxEditor生成训练样本的的合并tif图片：</p><p>（1）打开jTessBoxEditor，选择Tools-&gt;Merge TIFF，进入训练样本所在文件夹，选中要参与训练的样本图片：<br><img src="https://img-blog.csdnimg.cn/20190823091251831.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（2）点击 “打开” 后弹出保存对话框，选择保存在当前路径下，文件命名为 “zwp.test.exp0.tif” ，格式只有一种 “TIFF” 可选。</p><p>tif文面命名格式[lang].[fontname].exp[num].tif<br>lang是语言，fontname是字体，num为自定义数字。</p><p>比如我们要训练自定义字库 zwp，字体名test，那么我们把图片文件命名为 zwp.test.exp0.tif<br><img src="https://img-blog.csdnimg.cn/20190823091315868.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>4、使用tesseract生成.box文件：</p><p>在上一步骤生成的“zwp.test.exp0.tif”文件所在目录下打开命令行程序，执行下面命令,执行完之后会生成zwp.test.exp0.box文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tesseract zwp.test.exp0.tif zwp.test.exp0 -l chi_sim --psm 7 batch.nochop makebox</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/2019082309145728.png" alt="在这里插入图片描述"><br>其中，有关于–psm的训练参数，可在cmd中，tesseract –help-psm查询。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\lei-pc&gt;tesseract --help-psm</span><br><span class="line"></span><br><span class="line">Page segmentation modes:</span><br><span class="line">  0    Orientation and script detection (OSD) only.</span><br><span class="line">  1    Automatic page segmentation with OSD.</span><br><span class="line">  2    Automatic page segmentation, but no OSD, or OCR.</span><br><span class="line">  3    Fully automatic page segmentation, but no OSD. (Default)</span><br><span class="line">  4    Assume a single column of text of variable sizes.</span><br><span class="line">  5    Assume a single uniform block of vertically aligned text.</span><br><span class="line">  6    Assume a single uniform block of text.</span><br><span class="line">  7    Treat the image as a single text line.</span><br><span class="line">  8    Treat the image as a single word.</span><br><span class="line">  9    Treat the image as a single word in a circle.</span><br><span class="line"> 10    Treat the image as a single character.</span><br><span class="line"> 11    Sparse text. Find as much text as possible in no particular order.</span><br><span class="line"> 12    Sparse text with OSD.</span><br><span class="line"> 13    Raw line. Treat the image as a single text line,</span><br><span class="line">       bypassing hacks that are Tesseract-specific.</span><br><span class="line"></span><br><span class="line">  0    方向和脚本检测(OSD)</span><br><span class="line">  1    自动页面分割与OSD</span><br><span class="line">  2    自动页面分割，但没有OSD，而是OCR。</span><br><span class="line">  3    全自动页面分割，但没有OSD. (Default)</span><br><span class="line">  4    假设有一列大小不同的文本.</span><br><span class="line">  5    假设有一个垂直对齐的文本块.</span><br><span class="line">  6    假设只有一个统一的文本块.</span><br><span class="line">  7    将图像视为单个文本行.</span><br><span class="line">  8    将图像看作一个单个词.</span><br><span class="line">  9    将图像视为一个圆圈中的单个单词.</span><br><span class="line"> 10    将图像视为单个字符.</span><br><span class="line"> 11    Sparse text. 在没有特定顺序的情况下，尽可能多地查找文本.</span><br><span class="line"> 12    Sparse text with OSD.</span><br><span class="line"> 13    Raw line. 将图像视为单个文本行，绕过特定于tesseract的技巧。</span><br></pre></td></tr></table></figure><p>5、使用jTessBoxEditor矫正.box文件的错误：</p><p>.box文件记录了每个字符在图片上的位置和识别出的内容，训练前需要使用jTessBoxEditor调整字符的位置和内容。</p><p>打开jTessBoxEditor点击Box Editor -&gt;Open，打开步骤2中生成的“zwp.test.exp0.tif”，会自动关联到“zwp.test.exp0.box”文件，这两文件要求在同一目录下。调整完点击“save”保存修改。<br><img src="https://img-blog.csdnimg.cn/20190823091611487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>6、生成font_properties文件：（该文件没有后缀名）</p><p>（1）执行命令，执行完之后，会在当前目录生成font_properties文件</p><pre><code>echo test 0 0 0 0 0 &gt;font_properties</code></pre><p>（2）也可以手工新建一个名为font_properties的文本文件，输入内容 “test 0 0 0 0 0” 表示字体test的粗体、倾斜等共计5个属性。这里的“test”必须与“zwp.test.exp0.box”中的“test”名称一致。<br>7、使用tesseract生成.tr训练文件:</p><p>执行下面命令，执行完之后，会在当前目录生成zwp.test.exp0.tr文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tesseract zwp.test.exp0.tif zwp.test.exp0 nobatch box.train</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190823091729465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>8、生成字符集文件：</p><p>执行下面命令：执行完之后会在当前目录生成一个名为“unicharset”的文件。</p><pre><code>unicharset_extractor zwp.test.exp0.box</code></pre><p><img src="https://img-blog.csdnimg.cn/20190823091804830.png" alt="在这里插入图片描述"><br>9、生成shape文件：</p><p>执行下面命令，执行完之后，会生成 shapetable 和 zwp.unicharset 两个文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shapeclustering -F font_properties -U unicharset -O zwp.unicharset zwp.test.exp0.tr</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190823091827742.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>10、生成聚字符特征文件：</p><p>执行下面命令，会生成 inttemp、pffmtable、shapetable和zwp.unicharset四个文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mftraining -F font_properties -U unicharset -O zwp.unicharset zwp.test.exp0.tr</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190823091848668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>11、生成字符正常化特征文件：</p><p>执行下面命令，会生成 normproto 文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cntraining zwp.test.exp0.tr</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190823091941526.png" alt="在这里插入图片描述"><br>12、文件重命名：</p><p>重新命名inttemp、pffmtable、shapetable和normproto这四个文件的名字为[lang].xxx。</p><p>这里修改为zwp.inttemp、zwp.pffmtable、zwp.shapetable和zwp.normproto</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rename normproto zwp.normproto</span><br><span class="line">rename inttemp zwp.inttemp</span><br><span class="line">rename pffmtable zwp.pffmtable</span><br><span class="line">rename shapetable zwp.shapetable</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190823092006780.png" alt="在这里插入图片描述"><br>13、合并训练文件：</p><p>执行下面命令，会生成zwp.traineddata文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">combine_tessdata zwp.</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190823092029610.png" alt="在这里插入图片描述"><br>Log输出中的Offset 1、3、4、5、13这些项不是-1，表示新的语言包生成成功。</p><p>将生成的“zwp.traineddata”语言包文件复制到Tesseract-OCR 安装目录下的tessdata文件夹中，就可以使用训练生成的语言包进行图像文字识别了。</p><p> 14、测试：</p><p>输入下面命令，-l后面为训练生成的语言包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tesseract test.PNG test -l zwp</span><br></pre></td></tr></table></figure><p>附：最终所有的生成文件：<br><img src="https://img-blog.csdnimg.cn/20190823092121719.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="附：最终所有的生成文件："><br>可以发现命令很多 很复杂，这样训练较少样本的字符可以。但耗时耗力，大多是重复性工作。都是命令行，因此可以写一个批处理文件 自动化训练字符。<br>请移步：</p><p>转载自：<br>原文链接：<a href="https://blog.csdn.net/whatday/article/details/38493551" target="_blank" rel="noopener">https://blog.csdn.net/whatday/article/details/38493551</a></p>]]></content>
      
      
      <categories>
          
          <category> tesseract-ocr </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tesseract-ocr </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tesseract-OCR 4.1 LSTM训练流程</title>
      <link href="/2020/05/05/Tesseract-OCR%204.1%20LSTM%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/"/>
      <url>/2020/05/05/Tesseract-OCR%204.1%20LSTM%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>﻿曾参考此处-&gt;：<a href="https://blog.csdn.net/qq_30110069/article/details/98742701" target="_blank" rel="noopener">https://blog.csdn.net/qq_30110069/article/details/98742701</a></p><h3 id="Tesseract-OCR-4-1-LSTM训练流程-win10环境"><a href="#Tesseract-OCR-4-1-LSTM训练流程-win10环境" class="headerlink" title="Tesseract-OCR 4.1 LSTM训练流程 (win10环境)"></a>Tesseract-OCR 4.1 LSTM训练流程 (win10环境)</h3><h4 id="一、配置tesseract-4-1版本"><a href="#一、配置tesseract-4-1版本" class="headerlink" title="一、配置tesseract 4.1版本"></a>一、配置tesseract 4.1版本</h4><p>可通过自行编译源码或者下载安装文件安装tesseract。最新的tesseract 4.1 LSTM版无法找到安装文件，通过编译源码生成如下目录：</p><p><img src="https://img-blog.csdnimg.cn/20190917130859746.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下载源码VS2017自行编译tesseract 4.1教程： <a href="https://blog.csdn.net/kds0714/article/details/90755691" target="_blank" rel="noopener">https://blog.csdn.net/kds0714/article/details/90755691</a><br><strong>配置环境变量</strong></p><p>1、将<strong>bin</strong>目录加到系统变量<strong>Path</strong></p><p>2、将<strong>tessdata</strong>(训练的字库文件) 加到管理员用户变量，变量名<strong>TESSDATA_PREFIX</strong>，变量值为tessdata目录的路径<br><img src="https://img-blog.csdnimg.cn/20190917130918743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20190917130940994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>测试环境：</p><p>Win+R 分别输入:</p><p>tesseract –version</p><p>tesseract –list-langs</p><p>查看版本和当前含有的语言库，有返回值即可</p><h4 id="二、训练流程"><a href="#二、训练流程" class="headerlink" title="二、训练流程"></a>二、训练流程</h4><p><strong>基本流程：</strong></p><p>(1) jTessBoxEditor将样本合成tif文件</p><p>(2) 用已有的库识别tif文件，产生记录着数字内容，左上角坐标，宽高的.box文件。已有的库可以是下载的，也可以是自己训练出的</p><p>(3) 用jTessBoxEditor工具标注样本，调整.box文件数字内容和位置</p><p>(4) 在已有库的基础上训练样本，合成训练文件。</p><p>(5) 将合成后的文件放在tessdata文件夹中，通过代码调用来识别，测试识别率。</p><p><strong>训练可迭代</strong>：如用eng为基础，训练样本生成nml，nml仍含有eng的效果，但按理说效果可能会减弱些。所以可以加上不同种类的样本训练成一个大字库。</p><p><strong>准备：</strong></p><p>训练目录下，至少应含有合成的.tif文件。需要作为基础字库的原.traineddata文件，如eng.traineddata</p><p><strong>以官方下载的eng为例，训练nml.num.exp0</strong></p><p><strong>1、用jTessBoxEditor工具，将样本文件合并成.tif文件</strong>。规定如下命名格式：[lang].[fontname].exp[num].tif</p><p>如<strong>nml.num.exp0.tif</strong>，nml是语言名，num是字体名，exp0是版本号。训练过程应保持这种命名习惯</p><p>jTessBoxEditor工具的使用：</p><p><img src="https://img-blog.csdnimg.cn/20190917131020270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>Tools -&gt; Merge TIFF，选择文件类型为all the images，选中所有图片 -&gt; 命名为***.tif 合并为.tif文件<br><img src="https://img-blog.csdnimg.cn/2019091713103315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="1568101531560"></p><p><img src="https://img-blog.csdnimg.cn/2019091713105318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="1568101559988">)<img src="https://img-blog.csdnimg.cn/20190917131107330.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>2、在训练目录下打开cmd，用现有的字体库识别.tif文件，生成对应的.box文件</strong>。比如，用eng库识别样本，生成.box文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tesseract nml.num.exp0.tif nml.num.exp0 -l eng --psm 6 batch.nochop makebox</span><br></pre></td></tr></table></figure><p>输入命令后，会生成nml.um.exp0.box文件。</p><p>其中命令参数含义：</p><p>nml.num.exp0.tif 上一步生成的.tif 格式的文件</p><p>nml.num.exp0  指明要生成的.box文件的名称</p><p>-l eng表示识别使用的语言是eng，</p><p>–psm表示采用的识别模式，通常6比较好。可通过tesseract –help-psm查看所有的识别模式。6指的是假设去识别一个单一的文本块。</p><p><strong>3、jTessBoxEditor调整.box文件</strong><br><img src="https://img-blog.csdnimg.cn/20190917131125131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="1568105318525"><br>Box Editor -&gt; Open打开.tif文件，会关联同名的.box文件。调整数字时对应修改.box文件。<br><img src="https://img-blog.csdnimg.cn/2019091713114984.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>4、利用.tif和.box文件，生成.lstmf文件用于lstm训练</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tesseract nml.num.exp0.tif nml.num.exp0 -l eng --psm 6 lstm.train</span><br></pre></td></tr></table></figure><p>其中每个参数的意义为</p><p>nml.num.exp0.tif 上一步生成的.tif 格式的文件</p><p>nml.num.exp0  指明要生成的.lstmf文件的名称</p><p>运行后会多出一个nml.num.exp0.lstmf文件</p><p><strong>5、用已有的或官方下载的.traineddata文件中提取.lstm文件</strong></p><p><a href="https://github.com/tesseract-ocr/tessdata_best" target="_blank" rel="noopener">https://github.com/tesseract-ocr/tessdata_best</a> 从该链接中下载所需语言的.traineddata文件</p><p>注：一定要用从上述链接中下载的.traineddata文件，其他的.traineddata文件中提取.lstm文件无法进行训练。</p><p>将下载好的.traineddata文件拷贝到训练文件夹下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">combine_tessdata -e eng.traineddata eng.lstm</span><br></pre></td></tr></table></figure><p>运行上述代码，会从.traineddata文件中提取出eng.lstm 文件</p><p><strong>6. 创建文件，里边的内容为.lstmf文件的路径地址</strong><img src="https://img-blog.csdnimg.cn/20190917131707629.png" alt=""><br><strong>7、进行训练</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lstmtraining --model_output&#x3D;&quot;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\output\output&quot; --continue_from&#x3D;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\eng.lstm&quot; </span><br><span class="line">--train_listfile&#x3D;&quot;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\eng.training_files.txt&quot; --traineddata&#x3D;&quot;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\eng.traineddata&quot; </span><br><span class="line">--debug_interval -1 --max_iterations 2000</span><br></pre></td></tr></table></figure><p>各个参数的意义：</p><p> –model_output <strong>模型训练输出的路径</strong>，命令中我的训练目录是CTCCB24，新建output\output存放训练阶段文件和最终的字库</p><p>–continue_from <strong>训练从哪里开始</strong>，这里指定从第4步中提取的eng.lstm文件。也可从之前训练生成的阶段文件output_checkpoint开始。</p><p>–train_listfile 指定上一步创建的eng.training_files.txt文件路径</p><p>–traineddata 第4步中下载的.traineddata文件的路径</p><p>–debug_interval 当值为-1时，训练结束，会显示训练的一些结果参数</p><p>–max_iterations 指明训练遍历次数。最好使用这个参数：<strong>–target_error_rate 0.01 训练至错误率低于0.01</strong></p><p>训练结束后，在output文件夹中会生成一个output_checkpoint文件和多个类似output0.012_3.checkpoint的.checkpoint文件</p><p><strong>8、将checkpoint文件和.traineddata文件合并成新的.traineddata文件</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lstmtraining --stop_training --continue_from&#x3D;&quot;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\output\output_checkpoint&quot; </span><br><span class="line">--traineddata&#x3D;&quot;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\eng.traineddata&quot; --model_output&#x3D;&quot;F:\Test\AMyWork\ImgSampleLib\nomal\samples\CTCCB24\output\nml.traineddata&quot;</span><br></pre></td></tr></table></figure><p>各个参数的意义：</p><p>–stop_training 默认要有</p><p>–continue_from 上一步生成的output_checkpoint文件路径</p><p>–traineddata 第4步中下载的已有.traineddata文件的路径</p><p>–model_output zth.traineddata 输出的路径</p><p><strong>9、将新生成的nml.traineddata文件拷贝到tessdata文件夹下，通过代码进行识别</strong></p><p>注意：VS项目要配置好tesseract4.1的头文件、库目录，指定tessdata目录</p><p>一些质量不好的图片可能仍然需要二值化、滤波等预处理操作</p><p>bozhu不是大佬，各位看官可以结合其他博客使用。。。<br>项目过去了就没有及时复盘…有时间定会继续研究。<br>当然每人的问题可能跟环境等都有问题，当时是自己用VS2017编译的源码，后期会提供编译后文件。<br>当时调用时遇到过奇怪的问题：<br>当时是因为在自己电脑上编译，在硬件垃圾的服务器上调用。<br>出现 应用程序无法运行0xc000001d的问题，查找issues找到原因：编译tesseract时makefile文件默认开启cpu的AVX2指令集加速。但调用时若不支持AVX2指令集，就会报这个错误。<br><strong>只有3代以上cpu才支持AVX2指令集</strong><br>若有这种问题请移步:<br><a href="https://blog.csdn.net/Hu_helloworld/article/details/102612794" target="_blank" rel="noopener">https://blog.csdn.net/Hu_helloworld/article/details/102612794</a></p><p>有问题建议先查找issues，总能找到答案：<br><a href="https://github.com/tesseract-ocr/tesseract/issues" target="_blank" rel="noopener">https://github.com/tesseract-ocr/tesseract/issues</a></p>]]></content>
      
      
      <categories>
          
          <category> tesseract-ocr </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tesseract-ocr </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手把手教你用yolov3模型实现目标检测(三)-VOC数据集制作</title>
      <link href="/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%B8%89)-VOC%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/"/>
      <url>/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%B8%89)-VOC%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%B6%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p>﻿写在前面：</p><p>网上关于数据标注的文章已有很多，大多数都会有一些细节问题，比如怎样爬取网上的原始图片数据，如何批量重命名？数据集怎样划分为训练集，测试集，验证集？？？标注的数据放置的目录结构不对导致训练报错的问题等等，而这些问题，在本篇文章中都考虑到了，所以只要你按照步骤一步步来，并且使用本文中的代码，将会避免遇到上面所说的问题：</p><p>我们已经知道，物体检测，简言之就是框出图像中的目标物体，并给出框的位置和置信度，就像下图这样:<br><img src="https://img-blog.csdnimg.cn/2019112820291923.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>置信度在终端输出了：<br><img src="https://img-blog.csdnimg.cn/20191128202948303.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1、标注工具labelImg"><a href="#1、标注工具labelImg" class="headerlink" title="1、标注工具labelImg"></a>1、标注工具labelImg</h3><p>是的，当然要用强大的labelImg，貌似记得直接可以pip install labelImg，还是查一下如何安装吧，很简单的<br>界面长这个样子：<br><img src="https://img-blog.csdnimg.cn/20191128203519408.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下面我们<strong>标注PascalVOC数据集：</strong><br>首先下载VOC2007格式的原始数据集：<br><a href="http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar" target="_blank" rel="noopener">http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar</a><br><a href="http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar" target="_blank" rel="noopener">http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar</a><br>下载完成后，目录应该是这样式儿的：<br><img src="https://img-blog.csdnimg.cn/20191128204038263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>如果不需要其中的图片，直接删除，只保留空的目录结构。</p><p>其中，Annotations存放标注后的标签文件(.xml)<br>ImageSets存放你的训练集、测试集、验证集等的配置文件（文件中存放图片路径）<br>JPEGImages存放原始图片数据<br>SegmentationClass<br>SegmentationObject我们不使用<br>labelImg标注工具选择 打开目录-&gt;打开ImageSets目录，选择改变存放目录，存放xml到Annotations目录</p><p>labelImg使用简单<strong>快捷键</strong>：<br>A / D键，左右选择图片，W：开始标注，ctrl+s保存。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://blog.csdn.net/Hu_helloworld/article/details/103044737</span><br></pre></td></tr></table></figure><p>网上爬虫等下载到图片后，如何批量重命名？<br>一个小脚本：<br>食用时，请修改self.path重命名图片的路径，我会专门mkdir一个rename目录，免得出错。<br>而且重点是，VOC数据集格式是规定这样的：占6位数，所以必要是要修改dst那行的几个’000’,你一试就行<br><img src="https://img-blog.csdnimg.cn/2019112820524229.png" alt="在这里插入图片描述"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">class ImageRename():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.path = <span class="string">'/home/hujinlei/dev/YOLOv3-dev/darknet/scripts/VOCdevkit/VOC2007/rename'</span></span><br><span class="line"></span><br><span class="line">    def rename(self):</span><br><span class="line">        filelist = os.listdir(self.path)</span><br><span class="line">        total_num = len(filelist)</span><br><span class="line"></span><br><span class="line">        i = 2548</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> filelist:</span><br><span class="line">            <span class="keyword">if</span> item.endswith(<span class="string">'.jpg'</span>):</span><br><span class="line">                src = os.path.join(os.path.abspath(self.path), item)</span><br><span class="line">                dst = os.path.join(os.path.abspath(self.path), <span class="string">'000'</span> + format(str(i), <span class="string">'0&gt;3s'</span>) + <span class="string">'.jpg'</span>)</span><br><span class="line">                os.rename(src, dst)</span><br><span class="line">                <span class="built_in">print</span> (<span class="string">'converting %s to %s ...'</span>%(src, dst))</span><br><span class="line">                i = i + 1</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">'total %d to rename &amp; converted %d jpgs'</span> % (total_num, i))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    newname = ImageRename()</span><br><span class="line">    newname.rename()</span><br></pre></td></tr></table></figure><p>都标注好，重命名ok以后。<br>在VOC2007目录下，也就是这个目录下：<br><img src="https://img-blog.csdnimg.cn/20191128205523268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>以下脚本可以给整个数据集划分为：训练集、测试集、验证集.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">将voc_2007格式的数据集划分下训练集、测试集和验证集</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainval_percent = 0.96</span><br><span class="line">train_percent = 0.9</span><br><span class="line">xmlfilepath = <span class="string">'Annotations'</span></span><br><span class="line">txtsavepath = <span class="string">'ImageSets/Main'</span></span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num=len(total_xml)</span><br><span class="line">list=range(num)</span><br><span class="line">tv=int(num*trainval_percent)</span><br><span class="line">tr=int(tv*train_percent)</span><br><span class="line">trainval= random.sample(list,tv)</span><br><span class="line">train=random.sample(trainval,tr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ftrainval = open(<span class="string">'ImageSets/Main/trainval.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">ftest = open(<span class="string">'ImageSets/Main/test.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">ftrain = open(<span class="string">'ImageSets/Main/train.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">fval = open(<span class="string">'ImageSets/Main/val.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i  <span class="keyword">in</span> list:</span><br><span class="line">    name=total_xml[i][:-4]+<span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            ftrain.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftest.write(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest .close()</span><br></pre></td></tr></table></figure><p>会在目录下，生成ImageSets/Main/<br><img src="https://img-blog.csdnimg.cn/20191128205739103.png" alt="在这里插入图片描述"><br>最后，在工程项目的/scripts目录下，修改voc_label.py文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">import xml.etree.ElementTree as ET</span><br><span class="line">import pickle</span><br><span class="line">import os</span><br><span class="line">from os import listdir, getcwd</span><br><span class="line">from os.path import join</span><br><span class="line"><span class="comment">#将下面的sets和classes改为自己对应的</span></span><br><span class="line"><span class="comment">#sets=[('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test')]</span></span><br><span class="line"><span class="comment">#classes = ["aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"]</span></span><br><span class="line"></span><br><span class="line">sets=[(<span class="string">'2007'</span>, <span class="string">'train'</span>), (<span class="string">'2007'</span>, <span class="string">'val'</span>), (<span class="string">'2007'</span>, <span class="string">'test'</span>)]</span><br><span class="line">classes = [<span class="string">"Fire extinguisher"</span>,<span class="string">"Fire extinguisher box"</span>,<span class="string">"Fire hydrant"</span>,<span class="string">"trolley"</span>,<span class="string">"ladder"</span>]</span><br><span class="line"></span><br><span class="line">def convert(size, box):</span><br><span class="line">    dw = 1./(size[0])</span><br><span class="line">    dh = 1./(size[1])</span><br><span class="line">    x = (box[0] + box[1])/2.0 - 1</span><br><span class="line">    y = (box[2] + box[3])/2.0 - 1</span><br><span class="line">    w = box[1] - box[0]</span><br><span class="line">    h = box[3] - box[2]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="built_in">return</span> (x,y,w,h)</span><br><span class="line"></span><br><span class="line">def convert_annotation(year, image_id):</span><br><span class="line">    in_file = open(<span class="string">'VOCdevkit/VOC%s/Annotations/%s.xml'</span>%(year, image_id))</span><br><span class="line">    out_file = open(<span class="string">'VOCdevkit/VOC%s/labels/%s.txt'</span>%(year, image_id), <span class="string">'w'</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">'size'</span>)</span><br><span class="line">    w = int(size.find(<span class="string">'width'</span>).text)</span><br><span class="line">    h = int(size.find(<span class="string">'height'</span>).text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.iter(<span class="string">'object'</span>):</span><br><span class="line">        difficult = obj.find(<span class="string">'difficult'</span>).text</span><br><span class="line">        cls = obj.find(<span class="string">'name'</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls not <span class="keyword">in</span> classes or int(difficult)==1:</span><br><span class="line">            <span class="built_in">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">'bndbox'</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">'xmin'</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">'xmax'</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">'ymin'</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">'ymax'</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(str(cls_id) + <span class="string">" "</span> + <span class="string">" "</span>.join([str(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">wd = getcwd()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year, image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> not os.path.exists(<span class="string">'VOCdevkit/VOC%s/labels/'</span>%(year)):</span><br><span class="line">        os.makedirs(<span class="string">'VOCdevkit/VOC%s/labels/'</span>%(year))</span><br><span class="line">    image_ids = open(<span class="string">'VOCdevkit/VOC%s/ImageSets/Main/%s.txt'</span>%(year, image_set)).<span class="built_in">read</span>().strip().split()</span><br><span class="line">    list_file = open(<span class="string">'%s_%s.txt'</span>%(year, image_set), <span class="string">'w'</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">'%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\n'</span>%(wd, year, image_id))</span><br><span class="line">        convert_annotation(year, image_id)</span><br><span class="line">    list_file.close()</span><br><span class="line"></span><br><span class="line">os.system(<span class="string">"cat 2007_train.txt 2007_val.txt &gt; train.txt"</span>)</span><br><span class="line">os.system(<span class="string">"cat 2007_train.txt 2007_val.txt 2007_test.txt &gt; train.all.txt"</span>)</span><br></pre></td></tr></table></figure><p>运行此脚本，会在当前目录，产生以下文件：<br><img src="https://img-blog.csdnimg.cn/20191128210041486.png" alt="在这里插入图片描述"><br>其中，2007_test.txt测试集<br>    2007_train.txt训练集<br>    2007_val.txt验证集<br>    我们使用2007_test.txt和train.txt就可以。</p><p>=============================================================<br>日后在更</p>]]></content>
      
      
      <categories>
          
          <category> yolov3目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> yolov3目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手把手教你用yolov3模型实现目标检测教程(二)-样本数据获取</title>
      <link href="/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%BA%8C)-%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96/"/>
      <url>/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%BA%8C)-%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96/</url>
      
        <content type="html"><![CDATA[<p>写在前面：</p><p>听说你在训练时缺数据？不存在的o(<em>￣▽￣</em>)ブ</p><p><strong>数据来源于百度、google图片</strong></p><p>曾部分参考文章：<a href="https://blog.csdn.net/wobeatit/article/details/79559314" target="_blank" rel="noopener">https://blog.csdn.net/wobeatit/article/details/79559314</a></p><p><strong>因为google图片质量较好，推荐使用方法1：<br>利用googleimagesdownload工具爬取google 图片，<br>但需要fanqiang,能访问goolge图片，可以找插件/搭建亚马逊AWS服务器解决</strong></p><p>以下方法仅在ubuntu下测试过</p><h4 id="1、ubuntu下-使用工具google-images-download，爬取google-images"><a href="#1、ubuntu下-使用工具google-images-download，爬取google-images" class="headerlink" title="1、ubuntu下 使用工具google-images-download，爬取google images"></a>1、ubuntu下 使用工具google-images-download，爬取google images</h4><p><strong>若有梯子，能访问google images,可以采用这种方式，稳定，十分推荐！</strong><br>官方教程如下<br>项目地址：<a href="https://github.com/hardikvasa/google-images-download" target="_blank" rel="noopener">googleimagesdownload</a><br>工具安装：<a href="https://google-images-download.readthedocs.io/en/latest/installation.html" target="_blank" rel="noopener">安装googleimagesdownload</a><br>使用示例：<a href="https://google-images-download.readthedocs.io/en/latest/examples.html#" target="_blank" rel="noopener">使用示例</a></p><p>可直接pip安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install google_images_download</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">googleimagesdownload -k &quot;灭火器箱&quot; --size medium -l 1000 --chromedriver .&#x2F;chromedriver</span><br></pre></td></tr></table></figure><p>命令行   输入参数解释：<br>-k “要搜索的图片”<br>–size 指定图片大小，如medium<br>-l 限制下载的数量<br>–chromedriver 指定谷歌驱动的路径<br>Chrome驱动下载安装教程很多：<a href="https://blog.csdn.net/qq_41188944/article/details/79039690" target="_blank" rel="noopener">https://blog.csdn.net/qq_41188944/article/details/79039690</a></p><p>像这样 -l 限制下载1000张图片，因为图片版权的原因，实际下载到409张，可以更改搜索词再次下载。<br>google images 的图片质量较高，基本算是标注好的图片。<br>类似这种：<img src="https://img-blog.csdnimg.cn/20191113214031122.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>该工具会在终端目录创建download文件夹以放置爬取的图片</p><h4 id="2、python-脚本爬取百度图片"><a href="#2、python-脚本爬取百度图片" class="headerlink" title="2、python 脚本爬取百度图片"></a>2、python 脚本爬取百度图片</h4><p>(1) 安装 Chrome 浏览器 和 Chrome驱动<br>        Chrome驱动安装：<a href="https://blog.csdn.net/qq_41188944/article/details/79039690" target="_blank" rel="noopener">https://blog.csdn.net/qq_41188944/article/details/79039690</a></p><p>(2) pip install selenium安装selenium库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">#*******本脚本运行时需要本机安装 Chrome 浏览器以及Chrome的驱动，同时需要selenium库的支撑********</span><br><span class="line">from selenium import webdriver </span><br><span class="line">from selenium.webdriver.chrome.options import Options</span><br><span class="line">import time  </span><br><span class="line">import urllib.request</span><br><span class="line">from bs4 import BeautifulSoup as bs</span><br><span class="line">import re  </span><br><span class="line">import os  </span><br><span class="line">#****************************************************</span><br><span class="line">#base_url_part1 &#x3D; &#39;https:&#x2F;&#x2F;image.baidu.com&#x2F;search&#x2F;index?tn&#x3D;baiduimage&amp;ipn&#x3D;r&amp;ct&#x3D;201326592&amp;cl&#x3D;2&amp;lm&#x3D;-1&amp;st&#x3D;-1&amp;fm&#x3D;index&amp;fr&#x3D;&amp;hs&#x3D;0&amp;xthttps&#x3D;111111&amp;sf&#x3D;1&amp;fmq&#x3D;&amp;pv&#x3D;&amp;ic&#x3D;0&amp;nc&#x3D;1&amp;z&#x3D;&amp;se&#x3D;1&amp;showtab&#x3D;0&amp;fb&#x3D;0&amp;width&#x3D;&amp;height&#x3D;&amp;face&#x3D;0&amp;istype&#x3D;2&amp;ie&#x3D;utf-8&amp;word&#x3D;&#39;</span><br><span class="line">#base_url_part2 &#x3D; &#39;&amp;oq&#x3D;bagua&amp;rsp&#x3D;0&#39; # base_url_part1以及base_url_part2都是固定不变的，无需更改</span><br><span class="line">base_url_part1 &#x3D; &#39;https:&#x2F;&#x2F;www.shutterstock.com&#x2F;zh&#x2F;search&#x2F;&#39;</span><br><span class="line">base_url_part2 &#x3D; &#39;&#39; # base_url_part1以及base_url_part2都是固定不变的，无需更改</span><br><span class="line">search_query &#x3D; &#39;灭火器&#39; # 检索的关键词，可自行更改</span><br><span class="line">location_driver &#x3D; &#39;&#x2F;usr&#x2F;bin&#x2F;chromedriver&#39; # Chrome驱动程序在电脑中的位置</span><br><span class="line"> </span><br><span class="line">class Crawler:</span><br><span class="line">def __init__(self):</span><br><span class="line">self.url &#x3D; base_url_part1 + search_query + base_url_part2</span><br><span class="line"> </span><br><span class="line"># 启动Chrome浏览器驱动</span><br><span class="line">def start_brower(self):</span><br><span class="line">chrome_options &#x3D; Options()</span><br><span class="line">chrome_options.add_argument(&quot;--disable-infobars&quot;)</span><br><span class="line"># 启动Chrome浏览器  </span><br><span class="line">driver &#x3D; webdriver.Chrome(executable_path&#x3D;location_driver, chrome_options&#x3D;chrome_options)  </span><br><span class="line"># 最大化窗口，因为每一次爬取只能看到视窗内的图片</span><br><span class="line">driver.maximize_window()  </span><br><span class="line"># 浏览器打开爬取页面  </span><br><span class="line">driver.get(self.url)  </span><br><span class="line">return driver</span><br><span class="line"> </span><br><span class="line">def downloadImg(self, driver):  </span><br><span class="line">t &#x3D; time.localtime(time.time())</span><br><span class="line">foldername &#x3D; str(t.__getattribute__(&quot;tm_year&quot;)) + &quot;-&quot; + str(t.__getattribute__(&quot;tm_mon&quot;)) + &quot;-&quot; + \</span><br><span class="line"> str(t.__getattribute__(&quot;tm_mday&quot;)) # 定义文件夹的名字</span><br><span class="line">picpath &#x3D; &#39;&#x2F;home&#x2F;hujinlei&#x2F;dev&#x2F;DataSet&#x2F;BaiduImage&#x2F;%s&#39; %(foldername) # 下载到的本地目录</span><br><span class="line"># 路径不存在时创建一个 </span><br><span class="line">if not os.path.exists(picpath): os.makedirs(picpath)</span><br><span class="line"># 记录下载过的图片地址，避免重复下载</span><br><span class="line">img_url_dic &#x3D; &#123;&#125; </span><br><span class="line">x &#x3D; 0  </span><br><span class="line"># 当鼠标的位置小于最后的鼠标位置时,循环执行</span><br><span class="line">pos &#x3D; 0     </span><br><span class="line">for i in range(80): # 此处可自己设置爬取范围，本处设置为1，那么不会有下滑出现</span><br><span class="line">pos +&#x3D; 500 # 每次下滚500</span><br><span class="line">js &#x3D; &quot;document.documentElement.scrollTop&#x3D;%d&quot; %pos    </span><br><span class="line">driver.execute_script(js)  </span><br><span class="line">time.sleep(2)</span><br><span class="line"># 获取页面源码</span><br><span class="line">html_page &#x3D; driver.page_source</span><br><span class="line"># 利用Beautifulsoup4创建soup对象并进行页面解析</span><br><span class="line">soup &#x3D; bs(html_page, &quot;html.parser&quot;)</span><br><span class="line"># 通过soup对象中的findAll函数图像信息提取</span><br><span class="line">imglist &#x3D; soup.findAll(&#39;img&#39;, &#123;&#39;src&#39;:re.compile(r&#39;https:.*\.(jpg|png)&#39;)&#125;)</span><br><span class="line"> </span><br><span class="line">for imgurl in imglist:  </span><br><span class="line">if imgurl[&#39;src&#39;] not in img_url_dic:</span><br><span class="line">target &#x3D; &#39;&#123;&#125;&#x2F;&#123;&#125;.jpg&#39;.format(picpath, x)</span><br><span class="line">img_url_dic[imgurl[&#39;src&#39;]] &#x3D; &#39;&#39; </span><br><span class="line">urllib.request.urlretrieve(imgurl[&#39;src&#39;], target)  </span><br><span class="line">x +&#x3D; 1  </span><br><span class="line"></span><br><span class="line">def run(self):</span><br><span class="line">print (&#39;\t\t\t**************************************\n\t\t\t**\t\tWelcome to Use Spider\t\t**\n\t\t\t**************************************&#39;)  </span><br><span class="line">driver&#x3D;self.start_brower()</span><br><span class="line">self.downloadImg(driver)</span><br><span class="line">driver.close()</span><br><span class="line">print(&quot;Download has finished.&quot;)</span><br><span class="line"> </span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:  </span><br><span class="line">craw &#x3D; Crawler() </span><br><span class="line">craw.run()</span><br></pre></td></tr></table></figure><p>3、如何批量重命名下载的图片 ， 制作VOC COCO等数据集<br>以后补充</p>]]></content>
      
      
      <categories>
          
          <category> yolov3目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> yolov3目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手把手教你用yolov3模型实现目标检测教程(一) - 环境配置</title>
      <link href="/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%B8%80)-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/05/04/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8yolov3%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%99%E7%A8%8B(%E4%B8%80)-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>﻿## 手把手教你用yolov3模型实现目标检测(一)</p><p>写在前面：<br>由于项目需要，使用yolov3模型做了各种现实场景物体的目标检测。做完了过了好长时间，感觉有些遗忘，还是该留下点东西，方便自己查找，也希望能惠及他人。<br>同时，为了督促自己补充理论体系，尽量做到知其然知其所以然</p><h3 id="1、环境配置"><a href="#1、环境配置" class="headerlink" title="1、环境配置"></a>1、环境配置</h3><p>首先，本教程是完全在ubuntu 18.04下进行的，你能找到的成熟框架不外乎以下三个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;qqwweee&#x2F;keras-yolo3 ，基于keras编写</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;pjreddie&#x2F;darknet ，基于c++编写</span><br><span class="line"></span><br><span class="line">https:&#x2F;&#x2F;github.com&#x2F;AlexeyAB&#x2F;darknet ， 基于c++编写</span><br></pre></td></tr></table></figure><p>其中，第一个keras-yolo3需要搭建tensorflow-gpu,keras等很多环境。比较麻烦，有时间学习可以用这个。<br><strong>推荐使用</strong>第二个官方框架pjreddie/darknet，官网(教程)如下：<a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="noopener">https://pjreddie.com/darknet/yolo/</a><br>第三个AlexeyAB/darknet项目近期一直在维护，而且文档特别详细。但个人感觉第二个官方框架实践起来更简单。<br>建议训练和检测过程中有任何问题，先到第二第三个仓库的issues中查找，<strong>也许会找到你想要的</strong>。<br>好，那我们开始：<br>先下载该项目：<a href="https://github.com/pjreddie/darknet" target="_blank" rel="noopener">https://github.com/pjreddie/darknet</a></p><h4 id="CPU-GPU编译："><a href="#CPU-GPU编译：" class="headerlink" title="CPU/GPU编译："></a>CPU/GPU编译：</h4><p>编译过程中，检查环境：<br>我的环境：cmake version 3.10.2; 别的版本应该也可<br>Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49)<br>教程也很清楚哦：<a href="https://pjreddie.com/darknet/install/" target="_blank" rel="noopener">https://pjreddie.com/darknet/install/</a></p><p><strong>注意</strong>：darknet不支持gcc和g++6以上的版本，而ubuntu18.04默认安装的gcc-7<br>因此，需要将gcc和g++分别降级：<br><strong>（1）</strong> gcc/g++降级为4.8版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(1)在Ubuntu 16.04上安装老版gcc十分简单，直接用apt-get命令下载即可.</span><br><span class="line">sudo apt-get install gcc-4.8</span><br><span class="line">（2）安装完成后输入命令gcc --verison查看gcc的版本,此时还是高版本</span><br><span class="line">（3）查看版本gcc-4.8版本是否安装成功</span><br><span class="line">ls &#x2F;usr&#x2F;bin&#x2F;gcc*</span><br><span class="line">（4）输入命令设置默认版本:</span><br><span class="line">sudo update-alternatives --install &#x2F;usr&#x2F;bin&#x2F;gcc gcc &#x2F;usr&#x2F;bin&#x2F;gcc-4.8 100</span><br><span class="line">（5）查看默认结果（非必须）</span><br><span class="line">sudo update-alternatives --config gcc</span><br><span class="line">（6）最终gcc --version 发现变成4.8版本了</span><br><span class="line"></span><br><span class="line">g++的降级，只需把上面gcc改称g++。gcc和g++的版本应该必须一致。</span><br></pre></td></tr></table></figure><p><strong>CPU:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd darknet-master </span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>就完事了，一般不会有问题。</p><p><strong>GPU:</strong><br>yolov3是十分高效快速的！这点不用过多介绍，虽然CPU版本以及很快，但GPU号称快了500倍！<br>修改根目录下的makefile文件的GPU和CUDNN为1即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GPU&#x3D;1</span><br><span class="line">CUDNN&#x3D;1</span><br><span class="line">OPENCV&#x3D;0</span><br><span class="line">OPENMP&#x3D;0</span><br><span class="line">DEBUG&#x3D;0</span><br></pre></td></tr></table></figure><p>改完然后同样的，根目录 -&gt; make就ok了<br>我的环境：<br>ubuntu18.04+CUDA9.0+CUDNN7+nvidia1050 4G显存<br>安装教程：（很多链接）<br><a href="https://blog.csdn.net/Hu_helloworld/article/details/102614562" target="_blank" rel="noopener">https://blog.csdn.net/Hu_helloworld/article/details/102614562</a><br>CPU和GPU实测yolov3检测同一张图片，cpu到7、8s,GPU就是0.几s的量级<br>如果对于精确度要求不是特别高，而机器配置低对速度要求更高，建议使用yolov3-tiny版本（轻量，速度也可）</p><h3 id="2、下载与训练模型"><a href="#2、下载与训练模型" class="headerlink" title="2、下载与训练模型"></a>2、下载与训练模型</h3><p>yolov3.weights<br>模型文件包括<strong>.cfg</strong>配置文件和<strong>.weights</strong>权重文件<br>.cfg文件在项目中 /cfg目录<br>下载权重文件：<br><a href="https://pjreddie.com/media/files/yolov3.weights" target="_blank" rel="noopener">https://pjreddie.com/media/files/yolov3.weights</a><br>或者<br><a href="https://pjreddie.com/media/files/yolov3-tiny.weights" target="_blank" rel="noopener">https://pjreddie.com/media/files/yolov3-tiny.weights</a></p><h3 id="3、使用预训练模型测试目标检测"><a href="#3、使用预训练模型测试目标检测" class="headerlink" title="3、使用预训练模型测试目标检测"></a>3、使用预训练模型测试目标检测</h3><p>最简单的检测命令，在根目录下执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;darknet detect cfg&#x2F;yolov3.cfg yolov3.weights data&#x2F;dog.jpg</span><br></pre></td></tr></table></figure><p>另一种命令写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;darknet detector test cfg&#x2F;coco.data cfg&#x2F;yolov3.cfg yolov3.weights data&#x2F;dog.jpg</span><br></pre></td></tr></table></figure><p>您将看到以下输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">layer     filters    size              input                output</span><br><span class="line">    0 conv     32  3 x 3 &#x2F; 1   416 x 416 x   3   -&gt;   416 x 416 x  32  0.299 BFLOPs</span><br><span class="line">    1 conv     64  3 x 3 &#x2F; 2   416 x 416 x  32   -&gt;   208 x 208 x  64  1.595 BFLOPs</span><br><span class="line">    .......</span><br><span class="line">  105 conv    255  1 x 1 &#x2F; 1    52 x  52 x 256   -&gt;    52 x  52 x 255  0.353 BFLOPs</span><br><span class="line">  106 detection</span><br><span class="line">truth_thresh: Using default &#39;1.000000&#39;</span><br><span class="line">Loading weights from yolov3.weights...Done!</span><br><span class="line">data&#x2F;dog.jpg: Predicted in 0.029329 seconds.</span><br><span class="line">dog: 99%</span><br><span class="line">truck: 93%</span><br><span class="line">bicycle: 99%</span><br></pre></td></tr></table></figure><p>其中data文件夹中提供了一些示例图像，以备不时之需。尝试data/eagle.jpg，data/dog.jpg，data/person.jpg，或data/horses.jpg！<br>以下是我训练tiny模型的检测结果<br><img src="https://img-blog.csdnimg.cn/20191128200545339.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>到此位置我们可以使用官方提供的预训练模型进行目标检测，后面想在我们自己的场景下使用还需要自己训练样本，调整参数，调用自己的模型进行检测。<br>下篇介绍，标注自己的PASCAL VOC图片数据集，训练自己的yolov3-tiny模型。</p>]]></content>
      
      
      <categories>
          
          <category> yolov3目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> yolov3目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pandas将多列带时间戳的Series合并为单个DataFrame</title>
      <link href="/2020/05/04/pandas%E5%B0%86%E5%A4%9A%E5%88%97%E5%B8%A6%E6%97%B6%E9%97%B4%E6%88%B3%E7%9A%84Series%E5%90%88%E5%B9%B6%E4%B8%BA%E5%8D%95%E4%B8%AADataFrame/"/>
      <url>/2020/05/04/pandas%E5%B0%86%E5%A4%9A%E5%88%97%E5%B8%A6%E6%97%B6%E9%97%B4%E6%88%B3%E7%9A%84Series%E5%90%88%E5%B9%B6%E4%B8%BA%E5%8D%95%E4%B8%AADataFrame/</url>
      
        <content type="html"><![CDATA[<p>﻿<strong>背景：</strong><br>遇到这样的需求:<br>将多列这样以时间戳为index的Series数据拼接为整体的DataFrame（只带有一列index）<br>数据举例：<br>(1) 温度数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">2020-03-20 00:00:00    10.911639</span><br><span class="line">2020-03-20 00:30:00    10.561648</span><br><span class="line">2020-03-20 01:00:00    10.410831</span><br><span class="line">2020-03-20 01:30:00     9.993831</span><br><span class="line">2020-03-20 02:00:00     9.996133</span><br><span class="line">2020-03-20 02:30:00     9.807382</span><br><span class="line">2020-03-20 03:00:00     9.831737</span><br><span class="line">2020-03-20 03:30:00     9.767458</span><br><span class="line">2020-03-20 04:00:00     9.789868</span><br><span class="line">2020-03-20 04:30:00     9.993025</span><br><span class="line">2020-03-20 05:00:00    10.203707</span><br><span class="line">2020-03-20 05:30:00    10.460783</span><br><span class="line">2020-03-20 06:00:00    10.900585</span><br><span class="line">2020-03-20 06:30:00    11.154725</span><br><span class="line">2020-03-20 07:00:00    11.765203</span><br><span class="line">2020-03-20 07:30:00    12.377077</span><br><span class="line">2020-03-20 08:00:00    13.013389</span><br><span class="line">2020-03-20 08:30:00    13.685595</span><br><span class="line">2020-03-20 09:00:00    14.327092</span><br><span class="line">2020-03-20 09:30:00    14.862767</span><br><span class="line">2020-03-20 10:00:00    15.264174</span><br></pre></td></tr></table></figure><p>(2) 湿度数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">2020-03-20 00:00:00    30.071777</span><br><span class="line">2020-03-20 00:30:00    31.718174</span><br><span class="line">2020-03-20 01:00:00    32.415719</span><br><span class="line">2020-03-20 01:30:00    33.542252</span><br><span class="line">2020-03-20 02:00:00    33.725316</span><br><span class="line">2020-03-20 02:30:00    34.507023</span><br><span class="line">2020-03-20 03:00:00    34.402693</span><br><span class="line">2020-03-20 03:30:00    35.050728</span><br><span class="line">2020-03-20 04:00:00    35.082839</span><br><span class="line">2020-03-20 04:30:00    34.889389</span><br><span class="line">2020-03-20 05:00:00    34.481423</span><br><span class="line">2020-03-20 05:30:00    33.377774</span><br><span class="line">2020-03-20 06:00:00    31.306436</span><br><span class="line">2020-03-20 06:30:00    30.868772</span><br><span class="line">2020-03-20 07:00:00    29.368311</span><br><span class="line">2020-03-20 07:30:00    27.515762</span><br><span class="line">2020-03-20 08:00:00    24.488863</span><br><span class="line">2020-03-20 08:30:00    22.346596</span><br><span class="line">2020-03-20 09:00:00    19.126895</span><br><span class="line">2020-03-20 09:30:00    17.111340</span><br><span class="line">2020-03-20 10:00:00    13.799469</span><br></pre></td></tr></table></figure><p>解决的问题就是：保留一列时间戳作index，把剩下多列的Series.values拼接在一起。<br>（1）首先，找一组Series作为第一列,比如温度，先将series转换DataFrame:<br>self.preData[0]表示Series的温度数据，本文在self.preData列表中存放了5组上面说的Series数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frame &#x3D; &#123;&#39;Date Time&#39;: self.preData[0].index, &#39;Temperature&#39;: self.preData[0].values&#125;</span><br><span class="line">frame &#x3D; pd.DataFrame(frame)# 转换DataFrame</span><br></pre></td></tr></table></figure><p>（2）将第一列时间戳作为index</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">frame[&#39;Date Time&#39;] &#x3D; pd.to_datetime(frame[&#39;Date Time&#39;])</span><br><span class="line">frame.set_index(&#39;Date Time&#39;, inplace&#x3D;True)</span><br></pre></td></tr></table></figure><p>（3）按列拼接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">frame[&#39;Humidity&#39;] &#x3D; self.preData[1].values      # 温度列的DataFrame，与其他列的Series拼接</span><br><span class="line">frame[&#39;Wind&#39;] &#x3D; self.preData[2].values</span><br><span class="line">frame[&#39;WindSpeed&#39;] &#x3D; self.preData[3].values</span><br><span class="line">frame[&#39;itPower&#39;] &#x3D; self.preData[4].values</span><br></pre></td></tr></table></figure><p>因为列还算少，可直接指定列名。列太多可能要另想办法，希望对您有帮助~</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间序列教程之arima</title>
      <link href="/2020/05/04/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%99%E7%A8%8B%E4%B9%8Barima/"/>
      <url>/2020/05/04/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%99%E7%A8%8B%E4%B9%8Barima/</url>
      
        <content type="html"><![CDATA[<p>﻿最近接触时间序列较多，在借鉴很多人的知识之后，特此总结一下。目前关于时间序列数据分析预测大致有三种主流方法：<br><strong>①  ARIMA系列方法</strong><br><strong>②  facebook开源的Prophet模型</strong><br><strong>③  LSTM时间序列预测</strong></p><p>本系列希望在项目和实践的角度，用python实现上述三种方法并做出对比总结。如有不足之处，感谢指出，虚心改正。<br><strong>所需环境：</strong> win10/ubuntu均可，python3.6.x，pandas，numpy，tensorflow2.0，statsmodels，pmdarima…</p><h4 id="1、项目简介"><a href="#1、项目简介" class="headerlink" title="1、项目简介"></a>1、项目简介</h4><p>本文项目中所用数据为近一段时间内，间隔30分钟采样的气象数据（包括温度、湿度、风速、风向等数据）。在本文的理解中，arima方法仅支持单变量预测，也就是需要单独取出某列进行该列的预测。若想要多变量输入多变量输出，arima方法要拟合多个模型，再整合输入输出。</p><h4 id="2、数据介绍"><a href="#2、数据介绍" class="headerlink" title="2、数据介绍"></a>2、数据介绍</h4><p>数据是我从某气象网站爬取到的气象数据，已经做好数据清洗，后期我会附上数据链接，举例如下：<br><img src="https://img-blog.csdnimg.cn/20200414233949428.png" width="50%" alt=""/><br>表中单位：温度(华氏度)，湿度%，风向可转换角度，风速（mph）<br>读取csv数据，数据清洗：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">  def read_temperature():</span><br><span class="line">      # 以首列的日期时间作为时间戳 此处要转换成pandas的DatetimeIndex格式</span><br><span class="line">      data &#x3D; pd.read_csv(&#39;data&#x2F;test_2020.csv&#39;, usecols&#x3D;[0, 1, 2, 3, 4])</span><br><span class="line">      data[&#39;Date Time&#39;] &#x3D; pd.to_datetime(data[&#39;Date Time&#39;])</span><br><span class="line">      data.set_index(&#39;Date Time&#39;, inplace&#x3D;True)</span><br><span class="line">      data &#x3D; data[&#39;Temperature&#39;]  # DatetimeIndex对象</span><br><span class="line">      # 华氏度转摄氏度</span><br><span class="line">      for i in range(len(data)):</span><br><span class="line">          data[i] &#x3D; round(5 &#x2F; 9 * (data[i] - 32))</span><br><span class="line">      # 时间频率重采样</span><br><span class="line">      data &#x3D; data.resample(&#39;30T&#39;).mean()  # 更新频率30分钟，缺省值用临近的后一值补充</span><br><span class="line">      data &#x3D; data.fillna(data.bfill())</span><br><span class="line"># 显示数据</span><br><span class="line">      data.plot(figsize&#x3D;(15, 12))</span><br><span class="line">      plt.show()</span><br><span class="line">      return data</span><br></pre></td></tr></table></figure><p>当前数据图：<br><img src="https://img-blog.csdnimg.cn/20200416224817241.png" width="60%" alt=""/></p><h4 id="3、平稳性检验"><a href="#3、平稳性检验" class="headerlink" title="3、平稳性检验"></a>3、平稳性检验</h4><p>arima时间序列数据预测首先要保证数据的平稳性，肉眼可以看到当前数据可能有一定上升趋势。但还是要有数据量化这个平稳性，这里我们使用ADF平稳性检验，基于statsmodels库实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def adf_stability_test(self, data): </span><br><span class="line">    # ADF单位根检验：不存在单位根，表示数据平稳。且不能是白噪声数据(随机数)</span><br><span class="line">    x &#x3D; data</span><br><span class="line">    res &#x3D; ts.adfuller(x)</span><br><span class="line">    lb_res &#x3D; lb_test(x, None, True)[1]</span><br><span class="line"></span><br><span class="line">    tag &#x3D; False</span><br><span class="line">    for i in range(len(lb_res)):</span><br><span class="line">        if lb_res[i] &lt; 0.05:</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            print(&#39;序列为白噪声!&#39;)</span><br><span class="line">            tag &#x3D; True</span><br><span class="line">            break</span><br><span class="line">    if res[0] &lt; res[4][&#39;1%&#39;] and res[0] &lt; res[4][&#39;5%&#39;] and res[0] &lt; res[4][&#39;10%&#39;] and res[1] &lt; 0.05 and not tag:</span><br><span class="line">        print(&#39;平稳序列！非白噪声&#39;)</span><br><span class="line">        # plt.plot(lb_test(x, None, True)[1])</span><br><span class="line">        # plt.ylabel(&#39;p-Value&#39;)</span><br><span class="line">        # plt.show()</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure><p>adfuller方法返回值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(-6.260374222209651, 4.237742412839035e-08, 5, 906, &#123;&#39;1%&#39;: -3.4375883271133243, &#39;5%&#39;: -2.8647353885968214, &#39;10%&#39;: -2.568471435365895&#125;, 1615.9162778870964)</span><br></pre></td></tr></table></figure><p>ADF单位根检验，如果序列平稳，就不存在单位根；否则，就会存在单位根。该检验先假设序列不平稳，存在单位根。如果得到的显著性检验统计量小于三个置信度（10%，5%，1%），则对应有（90%，95，99%）的把握来拒绝原假设 -&gt;序列平稳。<br>adfuller的返回值意义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">adf：Test statistic，T检验，假设检验值。</span><br><span class="line">p-value：假设检验结果。</span><br><span class="line">usedlag：使用的滞后阶数。</span><br><span class="line">nobs：用于ADF回归和计算临界值用到的观测值数目。</span><br><span class="line">icbest：如果autolag不是None的话，返回最大的信息准则值。</span><br><span class="line">resstore：将结果合并为一个dummy。</span><br></pre></td></tr></table></figure><p>具体原理我也不是很懂，只需知道adf值，也就是本文的-6.260374222209651 均小于（10%，5%，1%）三个置信度的值，且p-value &lt; 0.05时能够较好的拒绝原假设，表示序列平稳。<br>若序列不平稳，需要对序列连续差分，直到序列平稳，对差分后的序列进行预测，再将预测结果逆差分，得到我们需要的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def stability_test(self):</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    flag &#x3D; False</span><br><span class="line">    if not self.adf_stability_test(self.data):</span><br><span class="line">        while not self.adf_stability_test(self.data):</span><br><span class="line">            count +&#x3D; 1</span><br><span class="line">            self.data &#x3D; self.data.diff(count)# 差分</span><br><span class="line">            self.data &#x3D; self.data.fillna(self.data.bfill())# 缺省值用后一值补充</span><br><span class="line">            flag &#x3D; True</span><br><span class="line">    print(&#39;经过&#123;&#125;次差分，序列平稳&#39;.format(count)) </span><br><span class="line">    return count, flag</span><br></pre></td></tr></table></figure><p>count是让序列变平稳的差分次数，<strong>也就是ARIMA(p,d,q)中的d</strong>，记录count值便于后面调pdq参数。flag记录是否经过差分，便于后期作逆差分还原数据。<br>差分操作很容易理解：原数列的后一项减去前一项得到的一组差数列。<br>相当于序列整体后移，空出第一位是空NAN，再与原序列做差</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0 1 2 3 4 5 6</span><br><span class="line">3 6 7 8 9 10 12 </span><br><span class="line"># 一阶差分</span><br><span class="line">0  1 2 3 4 5 6</span><br><span class="line">NAN  3 1 1 1 1 2</span><br></pre></td></tr></table></figure><p>我们知道arima或者是seasonal arima最重要的是（p,d,q）和（P,D,Q,S）这四个参数的确定。<br>而相对准确的方法是计算acf,pacf图，通过观察自相关图和偏相关图，确定拖尾还是截尾等什么鬼的…..我到现在还似懂非懂。总之了解下来是要肉眼观察参数，不能自动化调参…<br>但我们的数据是实时变化的，参数可能变动很大。自动化训练参数很有必要：</p><h4 id="4、模型参数训练"><a href="#4、模型参数训练" class="headerlink" title="4、模型参数训练"></a>4、模型参数训练</h4><p>目前了解两种自动确定参数方法：<br>1）<strong>网格搜索</strong>的方法：<br>感觉就是暴力搜索，用一些模型评价标准确定最优的参数，计算量很大复杂度高。不在乎效率也值得一试，此处用AIC准则评价模型，找出AIC评分最小的模型参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def temp_param_optimization(self, data):</span><br><span class="line">    paramBest &#x3D; []</span><br><span class="line">    warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line">    p &#x3D; q &#x3D; range(0, 3)# 限制pq范围</span><br><span class="line">    pdq &#x3D; [(x[0], self.d, x[1]) for x in list(itertools.product(p, q))]# 此处的d我们已经得到</span><br><span class="line">    seasonal_pdq &#x3D; [(x[0], self.d, x[1], s) for x in list(itertools.product(p, q))]# 此处的s是季节性参数，可根据数据指定，变化不大</span><br><span class="line">    </span><br><span class="line">    for param in pdq:</span><br><span class="line">        for param_seasonal in seasonal_pdq:</span><br><span class="line">            try:</span><br><span class="line">                mod &#x3D; sm.tsa.statespace.SARIMAX(data,</span><br><span class="line">                                                order&#x3D;param,</span><br><span class="line">                                                seasonal_order&#x3D;param_seasonal,</span><br><span class="line">                                                enforce_stationarity&#x3D;False,</span><br><span class="line">                                                enforce_invertibility&#x3D;False)</span><br><span class="line"></span><br><span class="line">                results &#x3D; mod.fit()</span><br><span class="line">                paramBest.append([param, param_seasonal, results.aic])</span><br><span class="line">                print(&#39;ARIMA&#123;&#125;x&#123;&#125;12 - AIC:&#123;&#125;&#39;.format(param, param_seasonal, results.aic))</span><br><span class="line">            except:</span><br><span class="line">                continue</span><br><span class="line">    # print(&#39;paramBest:&#39;, paramBest)</span><br><span class="line">    minAic &#x3D; sys.maxsize</span><br><span class="line">    for i in np.arange(len(paramBest)):</span><br><span class="line">        if paramBest[i][2] &lt; minAic:</span><br><span class="line">            minAic &#x3D; paramBest[i][2]</span><br><span class="line">    # print(&quot;minAic:&quot;, minAic)</span><br><span class="line">    for j in np.arange(len(paramBest)):</span><br><span class="line">        if paramBest[j][2] &#x3D;&#x3D; minAic:</span><br><span class="line">            return paramBest[j][0], paramBest[j][1]</span><br></pre></td></tr></table></figure><p><strong>2）pmdarima</strong><br>了解过时间序列发现，很多用R语言作时间序列预测的。因为R提供自动训练参数的库auto_arima。也是在项目后期才发现python也有类似的开源库pmdarima，貌似就是模仿R而来的。<br>直接pip install pmdarima -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>，pip安装要记得换源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def auto_parameters(self, data, s_num):</span><br><span class="line">    kpss_diff &#x3D; arima.ndiffs(data, alpha&#x3D;0.05, test&#x3D;&#39;kpss&#39;, max_d&#x3D;s_num)</span><br><span class="line">    adf_diff &#x3D; arima.ndiffs(data, alpha&#x3D;0.05, test&#x3D;&#39;adf&#39;, max_d&#x3D;s_num)</span><br><span class="line">    d &#x3D; max(kpss_diff, adf_diff)</span><br><span class="line">    D &#x3D; arima.nsdiffs(data, s_num)</span><br><span class="line">    </span><br><span class="line">    stepwise_model &#x3D; auto_arima(data, start_p&#x3D;1, start_q&#x3D;1,</span><br><span class="line">                                max_p&#x3D;9, max_q&#x3D;9, max_d&#x3D;3, m&#x3D;s_num,</span><br><span class="line">                                seasonal&#x3D;True, d&#x3D;d, D&#x3D;D, trace&#x3D;True,</span><br><span class="line">                                error_action&#x3D;&#39;ignore&#39;,</span><br><span class="line">                                suppress_warnings&#x3D;True,</span><br><span class="line">                                stepwise&#x3D;True)</span><br><span class="line">    print(&quot;AIC: &quot;, stepwise_model.aic())</span><br><span class="line">    print(stepwise_model.order)# (p,d,q)</span><br><span class="line">    print(stepwise_model.seasonal_order)# (P,D,Q,S)</span><br><span class="line">    print(stepwise_model.summary())# 详细模型</span><br><span class="line">    return stepwise_model.order, stepwise_model.seasonal_order</span><br></pre></td></tr></table></figure><p>十分方便的库，arima.ndiffs()，arima.nsdiffs()可以方便的求出最合适的d,和D参数。代码中s_num是自己指定的季节性参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">auto_arima(data, start_p&#x3D;1, start_q&#x3D;1,</span><br><span class="line">     max_p&#x3D;9, max_q&#x3D;9, max_d&#x3D;3, m&#x3D;s_num,</span><br><span class="line">     seasonal&#x3D;True, d&#x3D;d, D&#x3D;D, trace&#x3D;True,</span><br><span class="line">     error_action&#x3D;&#39;ignore&#39;,</span><br><span class="line">     suppress_warnings&#x3D;True,</span><br><span class="line">     stepwise&#x3D;True)</span><br></pre></td></tr></table></figure><p>start_p，start_q设置初始p,q参数，max_p，max_q最大值。stepwise=True貌似会直接选择最优参数。参数还有很多，请查阅官方api：<a href="https://alkaline-ml.com/pmdarima/index.html" target="_blank" rel="noopener">https://alkaline-ml.com/pmdarima/index.html</a><br>对比网格搜索的方法，本文觉得两种方法确定的参数几乎相同，但auto_arima训练参数特别快。同样的数据auto_arima要快一半以上。</p><h4 id="5、模型预测"><a href="#5、模型预测" class="headerlink" title="5、模型预测"></a>5、模型预测</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def model_prediction(self, data, param, s_param, n_steps, flag):</span><br><span class="line">    mod &#x3D; sm.tsa.statespace.SARIMAX(data,</span><br><span class="line">                                    order&#x3D;param,</span><br><span class="line">                                    seasonal_order&#x3D;s_param,</span><br><span class="line">                                    enforce_stationarity&#x3D;False,</span><br><span class="line">                                    enforce_invertibility&#x3D;False)</span><br><span class="line">    results &#x3D; mod.fit()</span><br><span class="line"></span><br><span class="line">    pred_uc &#x3D; results.get_forecast(steps&#x3D;n_steps)# n_steps可指定预测的步数(多少时间间隔)</span><br><span class="line">    pred_ci &#x3D; pred_uc.conf_int()</span><br><span class="line"></span><br><span class="line">    if flag:  # 还原差分</span><br><span class="line">        pred_res &#x3D; pd.Series([data[0]], index&#x3D;[data.index[0]]).append(pred_uc.predicted_mean).cumsum()</span><br><span class="line">        print(&quot;预测结果(℃):  &quot;, pred_res)</span><br><span class="line">        return pred_res</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;预测结果(℃):  &quot;, pred_uc.predicted_mean)</span><br><span class="line">        return pred_uc.predicted_mean</span><br></pre></td></tr></table></figure><p>传入参数param，s_param分别对应（pdq）(PDQS)<br>测试数据预测结果：<br><img src="https://img-blog.csdnimg.cn/20200417000446754.png" width="60%" alt=""/></p><hr><h4 id="4-21更新"><a href="#4-21更新" class="headerlink" title="4.21更新"></a>4.21更新</h4><p>感觉对于数据的季节性参数设置可能有点迷。比如文中提到的网格搜索的参数s和auto_arima的参数m都是要自己设置的，当然要根据所用数据的频率间隔来设置季节性。我的理解是数据规律的周期性呈现方式。比如，我用的是每30分钟的观测数据，一个月的数据。就可以设置为日周期性30<em>48=1440，一天共48个间隔，m或者s参数设置为48可能比较合适，但还是要针对数据具体分析。<br>如果各位同学可以*</em>科学上网**的话，<a href="https://robjhyndman.com/hyndsight/seasonal-periods/" target="_blank" rel="noopener">https://robjhyndman.com/hyndsight/seasonal-periods/</a>      这位博主关于季节性参数写的比较好！<br>针对一般情况的设置：<br><img src="https://img-blog.csdnimg.cn/20200421112656889.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0h1X2hlbGxvd29ybGQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>测试数据链接：<a href="https://pan.baidu.com/s/1G8lMZnVVe8_sUEdMlbetLg" target="_blank" rel="noopener">https://pan.baidu.com/s/1G8lMZnVVe8_sUEdMlbetLg</a></p><p>提取码: 77rj</p><p>但有些数据单位需要转换哈，像温度单位是华氏度</p>]]></content>
      
      
      <categories>
          
          <category> 时间序列预测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 时间序列预测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间序列教程之Prophet</title>
      <link href="/2020/05/04/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%99%E7%A8%8B%E4%B9%8BProphet/"/>
      <url>/2020/05/04/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%99%E7%A8%8B%E4%B9%8BProphet/</url>
      
        <content type="html"><![CDATA[<p>hi~ 这里是时间序列预测模型(二) 之 Prophet</p>]]></content>
      
      
      <categories>
          
          <category> 时间序列预测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 时间序列预测 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
